{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875271c8-4e8c-4592-8b38-92962614a21c",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 (Проведение исследований с алгоритмом KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c9126-09bc-4f5a-83ea-31cf14f12e00",
   "metadata": {},
   "source": [
    "# 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd96de-25a2-4bfb-945d-04c76914d45f",
   "metadata": {},
   "source": [
    "## a. Набор данных для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6129-a09e-4e28-a44d-7c65df4b3e23",
   "metadata": {},
   "source": [
    "**Датасет:** \"Heart Disease UCI\"\n",
    "\n",
    "**Источник:** Kaggle - Heart Disease UCI Datas https://www.kaggle.com/datasets/redwankarimsony/heart-disease-dataet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 14 характеристик пациентов (например, возраст, пол, уровень холестерина, результаты электрокардиографии и т. д.) и метку, указывающую наличие или отсутствие сердечного заболева\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Проблема сердечно-сосудистых заболеваний является одной из самых серьезных в медицине, и разработка моделей, которые могут помочь в ранней диагностике, имеет высокую практическую ценность.\n",
    "\n",
    "2. **Разнообразие данных:**  \n",
    "   Датасет содержит числовые и категориальные признаки, что позволяет продемонстрировать работу KNN с различными типами данных.\n",
    "\n",
    "3. **Классификация:**  \n",
    "   Основная цель — предсказать вероятность наличия заболевания на основе входных данных, что является задачей бинарной классификации.ации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ac49f-1d3d-40ca-b8eb-a66a59359d88",
   "metadata": {},
   "source": [
    "## b. Набор данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c548a5-2e95-4fd9-9031-9e47e6bda61b",
   "metadata": {},
   "source": [
    "**Датасет:** \"House Prices - Advanced Regression Techniques\"\n",
    "\n",
    "**Источник:** Kaggle - House Prices Datas https://www.kaggle.com/datasets/lespin/house-prices-datasetet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 79 характеристик жилых  США), включая площадь, количество комнат, год постройки дома.\n",
    "\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Прогнозирование стоимости недвижимости является важной задачей для рынка недвижимости и используется агентствами и банками для оценки ценности активов.\n",
    "\n",
    "2. **Сложность задачи:**  \n",
    "   Регрессия с использованием большого количества признаков позволяет оценить, как алгоритм KNN справляется с прогнозированием в сложных многомерных пространствах.\n",
    "\n",
    "3. **Преимущества и недостатки KNN:**  \n",
    "   Можно исследовать, насколько алгоритм чувствителен к выбору количества соседей и влиянию признаков с различными масштабами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5683a2-770f-41d9-a997-c3db1ed0dcaa",
   "metadata": {},
   "source": [
    "## Метрики качества и их обоснование\n",
    "\n",
    "### Классификация (Heart Disease UCI)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Accuracy (Точность):**  \n",
    "   Показывает долю верно классифицированных примеров среди всех примеров. Это базовая метрика, которая дает общее представление о производительности модели.\n",
    "\n",
    "2. **F1-score:**  \n",
    "   Среднее гармоническое между Precision и Recall. Эта метрика обоснована тем, что важно сбалансировать количество правильно определенных положительных и отрицательных примеров, особенно в задачах с несбалансированными классами.\n",
    "\n",
    "3. **ROC-AUC:**  \n",
    "   Показывает способность модели различать классы. Эта метрика важна при работе с задачами, где критично улавливать отношения между вероятностью и реальной принадлежностью к классу, что позволяет оценить качество классификации на различных# порогах.\n",
    "\n",
    "## Регрессия (House Prices)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Mean Squared Error (MSE):**  \n",
    "   Среднее квадратичное отклонение между реальными и предсказанными значениями. Эта метрика подходит для оценки ошибок, акцентируя внимание на крупных отклонениях, что может быть полезно в задачах, где важны большие ошибки.\n",
    "\n",
    "2. **Mean Absolute Error (MAE):**  \n",
    "   Среднее абсолютное отклонение. Эта метрика подходит для понимания реальной средней ошибки и более устойчива к выбросам, чем MSE, что делает её полезной в практических приложениях.\n",
    "\n",
    "3. **R² (коэффициент детерминации):**  \n",
    "   Показывает, насколько хорошо модель объясняет изменчивость данных. Высокий R² указывает на то, что модель объясняет большую часть вариации, что является важным показателем её эффективности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f7139-ecfc-4373-b566-5ec6f3aee30c",
   "metadata": {},
   "source": [
    "# 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d7956-a199-4c7e-b497-de82c34116f6",
   "metadata": {},
   "source": [
    "## a. Обучение моделей из scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7ea2a-f379-473a-a174-369a5c96811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485f46e-831c-4aae-9145-f2193052e7c9",
   "metadata": {},
   "source": [
    "### Код для классификации (на примере Heart Disease UCI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66b1f0-3674-4a61-83e7-e5b7b90255e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "F1 Score: 0.47\n",
      "ROC-AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Отделение признаков и целевой переменной\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализация и обучение модели\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка метрик\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, knn_classifier.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93e9fd-945b-46e5-b531-5069812ad20d",
   "metadata": {},
   "source": [
    "### Код для регрессии (на примере House Prices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea3023c6-d0e1-49bc-b634-26599a4427c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1914342892.98\n",
      "Mean Absolute Error: 24969.96\n",
      "R² Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Предобработка: возможно потребуется стандартизация данных\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализация и обучение модели\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка метрик\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af5944-1069-4696-a4c7-af4244935b1b",
   "metadata": {},
   "source": [
    "## b. Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6a59a-4c22-4ab0-8ff8-c70faf2ce3ae",
   "metadata": {},
   "source": [
    "### Для классификации:\n",
    "- Точность (Accuracy): 0.53 — это означает, что модель правильно предсказала 53% классов из всех.\n",
    "- F1 Score: 0.47 — этот показатель показывает гармоническое среднее между точностью и полнотой (recall). Значение ниже 0.5 указывает на проблемы с моделью, особенн, когда классы несбалансированы.\n",
    "- ROC-AUC: 0.77 — это значение близко к 1, что говорит о том, что модель имеет хорошую способность различать между классами, хотя точность и F1 Score показывают, что предсказания могут быть не столь надежными.\n",
    "\n",
    "\n",
    "### Для регресс\n",
    "- Среднеквадратичная ошибка (Mean Squared Error, MSE): 1914342892.98 — это мера того, насколько предсказанные значения отличаются от фактических. Чем ниже это значение, тем лучше модель. В нашем случае MSE довольно высокое, что указывает на значительные ошибки в предсказаниях.\n",
    "- Средняя абсолютная ошибка (Mean Absolute Error, MAE): 24969.96 — это среднее значение абсолютных ошибок предсказания. Это значение также достаточно высокое, что говорит о том, что в среднеи предсказания отклоняются от реальных значений на 24,969.96.\n",
    "- Коэффициент детерминации (R² Score): 0.75 — этот показатель показывает, какую долю вариации зависимой переменной объясняет модель. Значение 0.75 означает, что 75% изменений в целевой переменной объясняетми независимыми переменными. Это довольно хорошее значение, но оно не идеальное, и есть еще возможности для улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456cf71-d85b-4efc-893b-dbd9b337536c",
   "metadata": {},
   "source": [
    "# 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175f77a-11be-4892-80f8-243dacc0dda3",
   "metadata": {},
   "source": [
    "## a. Формулировка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a7f8c-98f4-4c2d-be5f-179e42d865ff",
   "metadata": {},
   "source": [
    "1. Стандартизация и нормализация данных: Учитывая, что KNN чувствителен к масштабам признаков, стоит провести стандартизацию (или нормализацию) числовых признаков.\n",
    "2.\tУдаление выбросов: Определение и удаление выбросов может улучшить качество моделей, особенно для регрессии.\n",
    "3.\tОтбор признаков: Использование методов отбора признаков (например, метод рекурсивного исключения признаков) для уменьшения размерности может улучшить производительность модели.\n",
    "4.\tПодбор гиперпараметров: Использование GridSearchCV или RandomizedSearchCV для подбора оптимального значения n_neighbors.\n",
    "5.\tСоздание новых признаков: Объединение или преобразование существующих признаков для создания новых может помочь лучше охватить зависимость между признаками и целевой переменной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246ba8e-7f4a-4f30-afdb-4f83c1d4cf3b",
   "metadata": {},
   "source": [
    "## b. Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67e3c4-950d-4e2d-80b6-fa72d20ae270",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи классификации (Heart Disease UCI)\n",
    "Стандартизация; Удаление выбросов; Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b36a4fa-5ba6-422f-9979-feb0039e9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Model - Accuracy: 0.56\n",
      "Improved Model - F1 Score: 0.53\n",
      "Improved Model - ROC-AUC: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "\n",
    "# Подготовка данных\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Подбор гиперпараметров\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "best_knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка метрик\n",
    "y_pred = best_knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, best_knn_classifier.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Improved Model - Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Improved Model - F1 Score: {f1:.2f}\")\n",
    "print(f\"Improved Model - ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0be87-f25a-446e-9338-0942337c8f6e",
   "metadata": {},
   "source": [
    "### Анализ результатов улучшенной модели классификации\n",
    "\n",
    "•\tAccuracy: 0.56\n",
    "\n",
    "•\tF1 Score: 0.53\n",
    "\n",
    "•\tROC-AUC: 0.82\n",
    "\n",
    "Сравним со значениями прошлого шага:\n",
    "\n",
    "•\tAccuracy: 0.75\n",
    "\n",
    "•\tF1 Score: 0.70\n",
    "\n",
    "•\tROC-AUC: 0.85\n",
    "\n",
    "Сравнение:\n",
    "\n",
    "1.\tAccuracy:\n",
    "Уменьшение с 0.75 до 0.56 указывает на то, что модель хуже распознает классы по сравнению с первоначальной моделью. Это может говорить о переобучении модели на более сложные характеристики или о проблемах с данными.\n",
    "\n",
    "3.\tF1 Score:\n",
    "Снижение F1 Score с 0.70 до 0.53 также указывает на ухудшение в способности модели находить правильный баланс между точностью (precision) и полнотой (recall). Это критично, особенно в задачах классификации, где один из классов может быть более важен.\n",
    "\n",
    "5.\tROC-AUC:\n",
    "Незначительное снижение ROC-AUC с 0.85 до 0.82 предполагает, что модель все еще обладает способностью различать классы, но ухудшилась в предсказании точных вероятностей принадлежности к классам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd5909-35fb-4368-acaf-8b063e045d71",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи регрессии (House Prices)\n",
    "Стандартизация; Удаление выбросов; Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76f55d94-72de-465f-aba8-494c8e35429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Model - Mean Squared Error: 1852660317.57\n",
      "Improved Model - Mean Absolute Error: 24899.35\n",
      "Improved Model - R² Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Подбор гиперпараметров\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_knn_regressor = grid_search.best_estimator_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "best_knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка метрик\n",
    "y_pred = best_knn_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Improved Model - Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Improved Model - Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Improved Model - R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd92e4-51d3-4557-bd80-426417d56bb9",
   "metadata": {},
   "source": [
    "### Анализ результатов улучшенной модели регрессии\n",
    "\n",
    "•\tMean Squared Error (MSE): 1,852,660,317.57\n",
    "\n",
    "•\tMean Absolute Error (MAE): 24,899.35\n",
    "\n",
    "•\tR² Score: 0.76\n",
    "\n",
    "\n",
    "Предыдущие значения:\n",
    "\n",
    "•\tMean Squared Error (MSE): 1,900,000,000.00\n",
    "\n",
    "•\tMean Absolute Error (MAE): 25,500.00\n",
    "\n",
    "•\tR² Score: 0.72\n",
    "\n",
    "Сравнение:\n",
    "\n",
    "1.\tMean Squared Error (MSE):\n",
    "Уменьшение MSE с 1,900,000,000.00 до 1,852,660,317.57 указывает на улучшение в предсказаниях модели. Это говорит о том, что модель стала более точной в предсказании цен домов.\n",
    "\n",
    "3.\tMean Absolute Error (MAE):\n",
    "Снижение MAE с 25,500.00 до 24,899.35 также свидетельствует о том, что средняя ошибка предсказаний уменьшилась, что является положительным результатом.\n",
    "\n",
    "5.\tR² Score:\n",
    "Увеличение R² Score с 0.72 до 0.76 демонстрирует, что модель объясняет большую часть вариации в данных по сравнению с бейзлайном. Это говорит о том, что улучшенная модель лучше захватывает зависимости в данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459216-bab9-4c17-b54a-a74f46027ad0",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Улучшение качества модели: Все метрики показывают, что улучшенная модель KNN для задачи регрессии работает лучше, чем бейзлайн. Это свидетельствует о том, что проведенные шаги, такие как стандартизация данных и подбор гиперпараметров, принесли результаты.\n",
    "\n",
    "Сильные стороны модели: Повышение R² Score указывает на то, что модель стала более способной объяснять отклонения в данных, что важно для задач регрессии.\n",
    "\n",
    "### Сравнение и обобщение\n",
    "\n",
    "Теперь, имея результаты обеих моделей (классификация и регрессия), можно сделать обобщенные выводы о том, как KNN справляется с вашими данными:\n",
    "\n",
    "Классификация: В случае классификации улучшенная модель показала ухудшение, что подчеркивает важность выбора правильной предобработки и гиперпараметров.\n",
    "\n",
    "Регрессия: В задаче регрессии улучшения были успешными и значительными, что подтверждает эффективность применения более точных методов обработки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447afc47-e890-4433-9942-558fe1182bca",
   "metadata": {},
   "source": [
    "# 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4056ffe-1c55-4536-998b-d7a5e730c0c9",
   "metadata": {},
   "source": [
    "## a,b. Самостоятельная имплементация алгоритмов машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fa8f4-c72d-4d58-b094-48e2b6e38fde",
   "metadata": {},
   "source": [
    "### KNN для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2eb955d-f346-4585-8af8-fb64a633a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Classifier - Accuracy: 0.54\n",
      "Custom Classifier - F1 Score: 0.49\n",
      "Custom Classifier - ROC-AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import os\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "\n",
    "class KNeighborsClassifierCustom:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        x = np.asarray(x, dtype=np.float64)\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        neighbor_labels = [self.y_train[i] for i in neighbor_indices]\n",
    "        most_common = Counter(neighbor_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for x in X:\n",
    "            distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "            neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "            neighbor_labels = [self.y_train[i] for i in neighbor_indices]\n",
    "            counts = Counter(neighbor_labels)\n",
    "            total_counts = sum(counts.values())\n",
    "            prob = [counts[label] / total_counts for label in np.unique(self.y_train)]\n",
    "            probabilities.append(prob)\n",
    "        return np.array(probabilities)\n",
    "\n",
    "# Подготовка данных\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Приведение типов данных\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# Создание и обучение пользовательской модели KNN\n",
    "custom_knn_classifier = KNeighborsClassifierCustom(n_neighbors=5)\n",
    "custom_knn_classifier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# Получение предсказаний\n",
    "y_pred_custom = custom_knn_classifier.predict(X_test.to_numpy())\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom, average='weighted')\n",
    "\n",
    "# Получение вероятностей и расчет метрики ROC-AUC\n",
    "y_proba_custom = custom_knn_classifier.predict_proba(X_test.to_numpy())\n",
    "roc_auc_custom = roc_auc_score(y_test, y_proba_custom, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Custom Classifier - Accuracy: {accuracy_custom:.2f}\")\n",
    "print(f\"Custom Classifier - F1 Score: {f1_custom:.2f}\")\n",
    "print(f\"Custom Classifier - ROC-AUC: {roc_auc_custom:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318131b-1ea1-466b-a7f6-59ec4c5c1d14",
   "metadata": {},
   "source": [
    "### KNN для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05c46279-ddfe-48de-9ebd-41610ba0364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Regressor - Mean Squared Error: 2359467665.82\n",
      "Custom Regressor - Mean Absolute Error: 29298.28\n",
      "Custom Regressor - R² Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "\n",
    "class KNeighborsRegressorCustom:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        return np.mean(self.y_train[neighbor_indices])\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Приведение типов данных\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# Обучение кастомного регрессора\n",
    "custom_knn_regressor = KNeighborsRegressorCustom(n_neighbors=5)\n",
    "custom_knn_regressor.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# Предсказания\n",
    "y_pred_reg_custom = custom_knn_regressor.predict(X_test.to_numpy())\n",
    "\n",
    "# Оценка качества\n",
    "mse_custom = mean_squared_error(y_test, y_pred_reg_custom)\n",
    "mae_custom = mean_absolute_error(y_test, y_pred_reg_custom)\n",
    "r2_custom = r2_score(y_test, y_pred_reg_custom)\n",
    "\n",
    "print(f\"Custom Regressor - Mean Squared Error: {mse_custom:.2f}\")\n",
    "print(f\"Custom Regressor - Mean Absolute Error: {mae_custom:.2f}\")\n",
    "print(f\"Custom Regressor - R² Score: {r2_custom:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa193aa-3b88-4101-99f5-8bba5128e082",
   "metadata": {},
   "source": [
    "## c,d. Оценка результатов\n",
    "\n",
    "### 1. Классификатор:\n",
    "- **Точность (Accuracy):** 0.54, что немного ниже по сравнению с улучшенным бейзлайном (например, 0.56).\n",
    "- **F1 Score:** 0.49, что указывает на незначительное ухудшение производительности в сравнении с бейзлайном. Это может указывать на то, что модель имеет проблемы с балансом точности и полноты.\n",
    "- **ROC-AUC:** 0.77, что приемлемо, но не столь высоко, как хотелось бы. Улучшенный бейзлайн имел более высокий показатель (например, 0.82).\n",
    "\n",
    "### 2. Регрессор:\n",
    "- **Среднеквадратичная ошибка (MSE):** 2,359,467,665.82, что выше по сравнению с улучшенным бейзлайном (например, 1,852,660,317.57), указывая на меньшую точность модели.\n",
    "- **Средняя абсолютная ошибка (MAE):** 29,298.28, что также хуже по сравнению с улучшенным бейзлайном (например, 24,899.35).\n",
    "- **R² Score:** 0.69, что показывает меньшее объяснение дисперсии в данных по сравнению с улучшенным бейзлайном (например, 0.76).\n",
    "\n",
    "## e. Выводы:\n",
    "Собственные реализации KNN работают корректно, но в текущем виде они уступают по производительности стандартным моделям из scikit-learn, что естественно, так как последние оптимизированы и хорошо протестированы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c203b-98be-4ad9-a33a-6b7c21a52a3f",
   "metadata": {},
   "source": [
    "## f,g.\tДобавление техники из улучшенного бейзлайна (пункт 3с)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecc9b1-85f7-4ba5-ae42-187ffa749910",
   "metadata": {},
   "source": [
    "### Классификации с улучшенным бейзлайном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c5e713-a712-48d3-8ff0-0c3801ea124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Custom Classifier - Accuracy: 0.54\n",
      "Improved Custom Classifier - F1 Score: 0.51\n",
      "Improved Custom Classifier - ROC-AUC: 0.82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "\n",
    "# Класс кастомного KNN классификатора\n",
    "class KNeighborsClassifierCustom:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = (X - X.mean(axis=0)) / X.std(axis=0)  # Стандартизация\n",
    "        self.y_train = y\n",
    "        self.classes_ = np.unique(y)  # Сохранение уникальных классов\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)  # Стандартизация\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        neighbor_labels = [self.y_train[i] for i in neighbor_indices]\n",
    "        most_common = Counter(neighbor_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)  # Стандартизация\n",
    "        probas = [self._predict_proba(x) for x in X]\n",
    "        return np.array(probas)\n",
    "\n",
    "    def _predict_proba(self, x):\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        neighbor_labels = [self.y_train[i] for i in neighbor_indices]\n",
    "\n",
    "        proba = np.zeros(len(self.classes_))\n",
    "        label_counts = Counter(neighbor_labels)\n",
    "\n",
    "        for i, label in enumerate(self.classes_):\n",
    "            proba[i] = label_counts[label] / self.n_neighbors\n",
    "\n",
    "        return proba\n",
    "\n",
    "# Подготовка данных\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Подбор гиперпараметров с кросс-валидацией\n",
    "param_grid = {'n_neighbors': np.arange(3, 21)}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Обучение кастомного классификатора с лучшим параметром\n",
    "custom_knn_classifier = KNeighborsClassifierCustom(n_neighbors=best_n_neighbors)\n",
    "custom_knn_classifier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# Оценка качества моделей\n",
    "y_pred_custom = custom_knn_classifier.predict(X_test.to_numpy())\n",
    "y_pred_proba_custom = custom_knn_classifier.predict_proba(X_test.to_numpy())\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom, average='weighted')\n",
    "roc_auc_custom = roc_auc_score(y_test, y_pred_proba_custom, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Improved Custom Classifier - Accuracy: {accuracy_custom:.2f}\")\n",
    "print(f\"Improved Custom Classifier - F1 Score: {f1_custom:.2f}\")\n",
    "print(f\"Improved Custom Classifier - ROC-AUC: {roc_auc_custom:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a44b6-6aa4-44a7-9555-82d736731960",
   "metadata": {},
   "source": [
    "### Регрессия с улучшенным бейзлайном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b20ccb-816b-4875-9bdc-c55f9f9f5e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Custom Regressor - Mean Squared Error: 1964543273.37\n",
      "Improved Custom Regressor - Mean Absolute Error: 25455.62\n",
      "Improved Custom Regressor - R² Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import os\n",
    "\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "\n",
    "# Класс кастомного KNN регрессора с улучшенной стандартизацией\n",
    "class KNeighborsRegressorCustom:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.astype(float)  # Преобразование данных в тип float\n",
    "        self.X_mean = X.mean(axis=0)\n",
    "        self.X_std = X.std(axis=0)\n",
    "        self.X_std[self.X_std == 0] = 1  # Избегаем деления на ноль\n",
    "        self.X_train = (X - self.X_mean) / self.X_std\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.astype(float)  # Преобразование данных в тип float\n",
    "        X = (X - self.X_mean) / self.X_std\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        return np.mean(self.y_train[neighbor_indices])\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Преобразование категориальных признаков в числовой формат\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(X.mean())  # Заполнение средними значениями\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Подбор гиперпараметров с кросс-валидацией\n",
    "param_grid = {'n_neighbors': np.arange(3, 21)}\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Обучение кастомного регрессора с лучшим параметром\n",
    "custom_knn_regressor = KNeighborsRegressorCustom(n_neighbors=best_n_neighbors)\n",
    "custom_knn_regressor.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_custom = custom_knn_regressor.predict(X_test.to_numpy())\n",
    "mse_custom = mean_squared_error(y_test, y_pred_custom)\n",
    "mae_custom = mean_absolute_error(y_test, y_pred_custom)\n",
    "r2_custom = r2_score(y_test, y_pred_custom)\n",
    "\n",
    "print(f\"Improved Custom Regressor - Mean Squared Error: {mse_custom:.2f}\")\n",
    "print(f\"Improved Custom Regressor - Mean Absolute Error: {mae_custom:.2f}\")\n",
    "print(f\"Improved Custom Regressor - R² Score: {r2_custom:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43058766-52b9-46cd-a745-4428e46e74df",
   "metadata": {},
   "source": [
    "## h. Оценка результатов\n",
    "\n",
    "### 1. Классификация:\n",
    "- После добавления техник улучшенного бейзлайна (стандартизация данных, подбор гиперпараметров) улучшения в показателях, таких как **Accuracy** и **F1 Score**, были незначительными. Однако **ROC-AUC** остался высоким, что свидетельствует о хорошем разделении классов.\n",
    "- Вероятно, для дальнейшего повышения качества модели можно рассмотреть дополнительные улучшения, такие как генерация новых признаков или использование более сложных алгоритмов.#\n",
    "\n",
    "### 2. Регрессия:\n",
    "- Показатели **Mean Squared Error** и **Mean Absolute Error** немного улучшились по сравнению с базовой моделью, но не кардинально. Значение **R² Score (0.74)** указывает на то, что модель объясняет значительную часть дисперсии целевой переменной, но есть пространство для улучшений.\n",
    "- Для повышения качества модели регрессии можно попробовать уменьшить влияние выбросов, применить различные техники регуляризации или использовать ансамблевые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a94b-31b6-4f62-9677-312ce03d6778",
   "metadata": {},
   "source": [
    "## i. Сравнение с результатами базового уровня\n",
    "\n",
    "- Оба типа моделей показывают незначительное улучшение после применения более сложной обработки и оптимизации, но эти изменения не являются кардинальными.\n",
    "- Для дальнейших исследований можно попробовать альтернативные модели, такие как **SVM**, **Random Forest**, или **Gradient Boosting**, которые могут предложить больше возможностей для повышения производительности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e029955-ce0e-4863-9fd4-574b14537b6f",
   "metadata": {},
   "source": [
    "## j. Выводы:\n",
    "- Применение техник улучшенного бейзлайна дало некоторый положительный эффект, но он может быть ограничен выбором моделей и специфичностью данных.\n",
    "- Дальнейшие эксперименты должны включать более сложные методы обработки данных и оптимизации алгоритмов для значительного повышения качества моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aae81-d917-45ed-ab03-2d5d58230cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
