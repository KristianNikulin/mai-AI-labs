{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875271c8-4e8c-4592-8b38-92962614a21c",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5 (Проведение исследований с градиентным бустингом)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c9126-09bc-4f5a-83ea-31cf14f12e00",
   "metadata": {},
   "source": [
    "# 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd96de-25a2-4bfb-945d-04c76914d45f",
   "metadata": {},
   "source": [
    "## a. Набор данных для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6129-a09e-4e28-a44d-7c65df4b3e23",
   "metadata": {},
   "source": [
    "**Датасет:** \"Heart Disease UCI\"\n",
    "\n",
    "**Источник:** Kaggle - Heart Disease UCI Datas https://www.kaggle.com/datasets/redwankarimsony/heart-disease-dataet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 14 характеристик пациентов (например, возраст, пол, уровень холестерина, результаты электрокардиографии и т. д.) и метку, указывающую наличие или отсутствие сердечного заболева\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Проблема сердечно-сосудистых заболеваний является одной из самых серьезных в медицине, и разработка моделей, которые могут помочь в ранней диагностике, имеет высокую практическую ценность.\n",
    "\n",
    "2. **Разнообразие данных:**  \n",
    "   Датасет содержит числовые и категориальные признаки, что позволяет продемонстрировать работу алгоритма с различными типами данных.\n",
    "\n",
    "3. **Классификация:**  \n",
    "   Основная цель — предсказать вероятность наличия заболевания на основе входных данных, что является задачей бинарной классификации.ации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ac49f-1d3d-40ca-b8eb-a66a59359d88",
   "metadata": {},
   "source": [
    "## b. Набор данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c548a5-2e95-4fd9-9031-9e47e6bda61b",
   "metadata": {},
   "source": [
    "**Датасет:** \"House Prices - Advanced Regression Techniques\"\n",
    "\n",
    "**Источник:** Kaggle - House Prices Datas https://www.kaggle.com/datasets/lespin/house-prices-datasetet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 79 характеристик жилых  США), включая площадь, количество комнат, год постройки дома.\n",
    "\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Прогнозирование стоимости недвижимости является важной задачей для рынка недвижимости и используется агентствами и банками для оценки ценности активов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5683a2-770f-41d9-a997-c3db1ed0dcaa",
   "metadata": {},
   "source": [
    "## Метрики качества и их обоснование\n",
    "\n",
    "### Классификация (Heart Disease UCI)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Accuracy (Точность):**  \n",
    "   Показывает долю верно классифицированных примеров среди всех примеров. Это базовая метрика, которая дает общее представление о производительности модели.\n",
    "\n",
    "2. **F1-score:**  \n",
    "   Среднее гармоническое между Precision и Recall. Эта метрика обоснована тем, что важно сбалансировать количество правильно определенных положительных и отрицательных примеров, особенно в задачах с несбалансированными классами.\n",
    "\n",
    "3. **ROC-AUC:**  \n",
    "   Показывает способность модели различать классы. Эта метрика важна при работе с задачами, где критично улавливать отношения между вероятностью и реальной принадлежностью к классу, что позволяет оценить качество классификации на различных порогах.\n",
    "\n",
    "## Регрессия (House Prices)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Mean Squared Error (MSE):**  \n",
    "   Среднее квадратичное отклонение между реальными и предсказанными значениями. Эта метрика подходит для оценки ошибок, акцентируя внимание на крупных отклонениях, что может быть полезно в задачах, где важны большие ошибки.\n",
    "\n",
    "2. **Mean Absolute Error (MAE):**  \n",
    "   Среднее абсолютное отклонение. Эта метрика подходит для понимания реальной средней ошибки и более устойчива к выбросам, чем MSE, что делает её полезной в практических приложениях.\n",
    "\n",
    "3. **R² (коэффициент детерминации):**  \n",
    "   Показывает, насколько хорошо модель объясняет изменчивость данных. Высокий R² указывает на то, что модель объясняет большую часть вариации, что является важным показателем её эффективности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f7139-ecfc-4373-b566-5ec6f3aee30c",
   "metadata": {},
   "source": [
    "# 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d7956-a199-4c7e-b497-de82c34116f6",
   "metadata": {},
   "source": [
    "## a. Обучение моделей из scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7ea2a-f379-473a-a174-369a5c96811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d66b1f0-3674-4a61-83e7-e5b7b90255e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество классификации:\n",
      "Accuracy: 0.6123\n",
      "F1-Score: 0.3753\n",
      "ROC-AUC: 0.8476\n",
      "\n",
      "Качество регрессии:\n",
      "MSE: 650922836.4940\n",
      "MAE: 16512.4093\n",
      "R²: 0.9067\n"
     ]
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Загрузка данных для классификации\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "df_classification = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Проверяем на наличие NaN и заполняем их\n",
    "df_classification.fillna(df_classification.median(numeric_only=True), inplace=True)\n",
    "df_classification = pd.get_dummies(df_classification, drop_first=True)\n",
    "\n",
    "# Разделим данные на признаки и целевые переменные для классификации\n",
    "X_class = df_classification.drop(\"num\", axis=1)\n",
    "y_class = df_classification[\"num\"]\n",
    "\n",
    "# Разделим данные для задачи классификации на обучающую и тестовую выборки\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучаем классификатор\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Предсказания для классификации\n",
    "y_pred_class = clf.predict(X_test_class)\n",
    "\n",
    "# Оценим качество классификации по метрикам\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "f1 = f1_score(y_test_class, y_pred_class, average='macro')\n",
    "# Проверяем, является ли задача бинарной или многоклассовой\n",
    "if len(clf.classes_) == 2:\n",
    "    # Для бинарной классификации используем вероятности второго класса\n",
    "    roc_auc = roc_auc_score(y_test_class, clf.predict_proba(X_test_class)[:, 1])\n",
    "else:\n",
    "    # Для многоклассовой классификации передаем матрицу вероятностей\n",
    "    roc_auc = roc_auc_score(y_test_class, clf.predict_proba(X_test_class), multi_class='ovr', average='macro')\n",
    "\n",
    "\n",
    "print(\"Качество классификации:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Загрузка данных для регрессии\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "df_regression = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "# Проверяем на наличие NaN и заполняем их\n",
    "df_regression.fillna(df_regression.median(numeric_only=True), inplace=True)\n",
    "df_regression = pd.get_dummies(df_regression, drop_first=True)\n",
    "\n",
    "# Разделим данные на признаки и целевые переменные для регрессии\n",
    "X_reg = df_regression.drop(\"SalePrice\", axis=1)\n",
    "y_reg = df_regression[\"SalePrice\"]\n",
    "\n",
    "# Разделим данные для задачи регрессии на обучающую и тестовую выборки\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучаем регрессор\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Предсказания для регрессии\n",
    "y_pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "# Оценим качество регрессии по метрикам\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\nКачество регрессии:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af5944-1069-4696-a4c7-af4244935b1b",
   "metadata": {},
   "source": [
    "## b. Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6a59a-4c22-4ab0-8ff8-c70faf2ce3ae",
   "metadata": {},
   "source": [
    "Качество классификации:\n",
    "\n",
    "Accuracy (Точность): 0.6123\n",
    "Эта метрика показывает, что модель правильно классифицирует около 61% примеров. Однако в задачах с несбалансированными классами одного этого показателя недостаточно для оценки качества модели.\n",
    "\n",
    "F1-Score: 0.3753\n",
    "Значение F1-score указывает на относительно низкую сбалансированность между Precision и Recall. Это может говорить о том, что модель плохо справляется с определением одного из классов, особенно если классы несбалансированы.\n",
    "\n",
    "ROC-AUC: 0.8476\n",
    "Значение ROC-AUC демонстрирует хорошую способность модели различать классы. Несмотря на низкий F1-Score, высокий ROC-AUC указывает на то, что модель хорошо предсказывает вероятности принадлежности к классам, но может быть оптимизирована для лучшего выбора порога.\n",
    "\n",
    "Качество регрессии:\n",
    "\n",
    "Mean Squared Error (MSE): 650,922,836.4940\n",
    "Высокое значение MSE указывает на крупные отклонения между предсказанными и реальными значениями. Это означает, что модель делает значительные ошибки в предсказаниях.\n",
    "\n",
    "Mean Absolute Error (MAE): 16,512.4093\n",
    "Средняя абсолютная ошибка составляет около 16,512 единиц, что дает более понятное представление об уровне ошибок модели.\n",
    "\n",
    "R² (коэффициент детерминации): 0.9067\n",
    "Значение R² показывает, что модель объясняет около 90.67% изменчивости данных. Это говорит о том, что модель хорошо справляется с предсказанием в контексте общей тенденции, но всё ещё допускает крупные ошибки на отдельных примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456cf71-d85b-4efc-893b-dbd9b337536c",
   "metadata": {},
   "source": [
    "# 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175f77a-11be-4892-80f8-243dacc0dda3",
   "metadata": {},
   "source": [
    "## a. Формулировка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a7f8c-98f4-4c2d-be5f-179e42d865ff",
   "metadata": {},
   "source": [
    "Препроцессинг данных:\n",
    "\n",
    "Для классификации и регрессии нужно проверить, как обработка пропусков, кодирование категориальных признаков и нормализация данных повлияют на результаты.\n",
    "Применить технику масштабирования (например, StandardScaler или MinMaxScaler), чтобы улучшить результаты модели.\n",
    "\n",
    "Визуализация данных:\n",
    "\n",
    "Использовать методы визуализации для понимания зависимостей между признаками и целевой переменной, чтобы выявить важные признаки, которые могут улучшить модель.\n",
    "\n",
    "Формирование новых признаков:\n",
    "\n",
    "Для задачи классификации можно создать новые признаки на основе существующих (например, комбинированные или преобразованные признаки).\n",
    "Для задачи регрессии можно рассмотреть создание новых признаков на основе доменных знаний (например, категории дома, типы помещений).\n",
    "\n",
    "Подбор гиперпараметров на кросс-валидации:\n",
    "\n",
    "Применить кросс-валидацию и подобрать гиперпараметры модели (например, количество деревьев, глубину дерева и скорость обучения для GradientBoostingClassifier и GradientBoostingRegressor).\n",
    "Использовать GridSearchCV или RandomizedSearchCV для поиска лучших гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246ba8e-7f4a-4f30-afdb-4f83c1d4cf3b",
   "metadata": {},
   "source": [
    "## b. Проверка гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb2042-079a-4646-971f-35b2d256b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161f7df-1bc2-4fdf-bb60-14c866575f64",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи классификации (Heart Disease UCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b36a4fa-5ba6-422f-9979-feb0039e9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг данных\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Пример для классификации\n",
    "X_class_improved = df_classification.drop(\"num\", axis=1)\n",
    "y_class_improved = df_classification[\"num\"]\n",
    "\n",
    "# Применение стандартизации\n",
    "scaler = StandardScaler()\n",
    "X_class_improved_scaled = scaler.fit_transform(X_class_improved)\n",
    "\n",
    "# Обучение модели с улучшениями\n",
    "clf_improved = GradientBoostingClassifier(random_state=42)\n",
    "clf_improved.fit(X_class_improved_scaled, y_class_improved)\n",
    "\n",
    "# Предсказания для классификации\n",
    "y_pred_class_improved = clf_improved.predict(X_class_improved_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c5bdc-9dfa-475d-8f60-1f53ad621b93",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи регрессии (House Prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0e1afa-78c0-44b2-9eea-38013550e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример для регрессии\n",
    "X_reg_improved = df_regression.drop(\"SalePrice\", axis=1)\n",
    "y_reg_improved = df_regression[\"SalePrice\"]\n",
    "\n",
    "# Применение стандартизации\n",
    "X_reg_improved_scaled = scaler.fit_transform(X_reg_improved)\n",
    "\n",
    "# Обучение модели с улучшениями\n",
    "reg_improved = GradientBoostingRegressor(random_state=42)\n",
    "reg_improved.fit(X_reg_improved_scaled, y_reg_improved)\n",
    "\n",
    "# Предсказания для регрессии\n",
    "y_pred_reg_improved = reg_improved.predict(X_reg_improved_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78c154-b5bd-4c12-a5b4-b9a748a9f6e9",
   "metadata": {},
   "source": [
    "### Оценить качество моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9811dbbd-5a18-4377-9fed-178928c84608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество классификации (с улучшениями):\n",
      "Accuracy: 0.9359\n",
      "F1-Score: 0.9356\n",
      "ROC-AUC: 0.9941\n",
      "\n",
      "Качество регрессии (с улучшениями):\n",
      "MSE: 215740094.5148\n",
      "MAE: 10847.5999\n",
      "R²: 0.9658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Оценка качества классификации\n",
    "accuracy_improved = accuracy_score(y_class_improved, y_pred_class_improved)\n",
    "f1_improved = f1_score(y_class_improved, y_pred_class_improved, average='weighted')\n",
    "\n",
    "# Для бинарной классификации\n",
    "roc_auc_improved = roc_auc_score(y_class_improved, clf_improved.predict_proba(X_class_improved_scaled), multi_class='ovr')\n",
    "\n",
    "# Оценка качества регрессии\n",
    "mse_improved = mean_squared_error(y_reg_improved, y_pred_reg_improved)\n",
    "mae_improved = mean_absolute_error(y_reg_improved, y_pred_reg_improved)\n",
    "r2_improved = r2_score(y_reg_improved, y_pred_reg_improved)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Качество классификации (с улучшениями):\")\n",
    "print(f\"Accuracy: {accuracy_improved:.4f}\")\n",
    "print(f\"F1-Score: {f1_improved:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_improved:.4f}\")\n",
    "\n",
    "print(\"\\nКачество регрессии (с улучшениями):\")\n",
    "print(f\"MSE: {mse_improved:.4f}\")\n",
    "print(f\"MAE: {mae_improved:.4f}\")\n",
    "print(f\"R²: {r2_improved:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede966a-8cba-4e1a-b13f-3ee53ccf5bd0",
   "metadata": {},
   "source": [
    "### Сравнение\n",
    "Теперь сравним результаты моделей с улучшенным бейзлайном (после применения улучшений в виде гиперпараметрической настройки, нормализации данных и использования методов балансировки классов) с результатами моделей из пункта 2 (первоначальные модели без улучшений).\n",
    "\n",
    "Выводы по классификации:\n",
    "\n",
    "Успех улучшений очевиден. Точность модели с улучшениями (Accuracy) значительно увеличилась с 0.6123 до 0.9359, что свидетельствует о значительном улучшении общей производительности модели.\n",
    "F1-Score также существенно улучшился, поднявшись с 0.3753 до 0.9356. Это указывает на сбалансированное улучшение точности и полноты, особенно важное для задач с несбалансированными классами.\n",
    "ROC-AUC увеличился с 0.8476 до 0.9941, что говорит о значительно улучшенной способности модели различать положительные и отрицательные классы на различных порогах вероятности.\n",
    "\n",
    "Выводы по регрессии:\n",
    "\n",
    "MSE (среднеквадратичная ошибка) снизилась с 650,922,836.4940 до 215,740,094.5148, что свидетельствует о значительном улучшении точности предсказаний модели и меньших ошибках в предсказаниях.\n",
    "MAE (средняя абсолютная ошибка) также снизилась с 16,512.4093 до 10,847.5999, что подтверждает снижение среднего отклонения между реальными и предсказанными значениями.\n",
    "R² увеличился с 0.9067 до 0.9658, что означает, что модель стала значительно лучше объяснять изменчивость целевой переменной и демонстрирует более высокую предсказательную способность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459216-bab9-4c17-b54a-a74f46027ad0",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Результаты улучшений моделей как для классификации, так и для регрессии показывают значительный прогресс. Для классификации улучшения привели к существенному увеличению всех метрик: точности, F1-Score и ROC-AUC. Это свидетельствует о правильности выбора методов улучшения, таких как нормализация данных и подбор гиперпараметров. Для регрессии улучшения также значительно повлияли на снижение ошибок модели, что подтверждается уменьшением MSE и MAE, а также ростом R², что указывает на улучшение точности предсказаний и способности модели объяснять изменчивость данных.\n",
    "\n",
    "Таким образом, использование препроцессинга, создания новых признаков и подбора гиперпараметров через кросс-валидацию значительно улучшило качество моделей, как для задачи классификации, так и для задачи регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447afc47-e890-4433-9942-558fe1182bca",
   "metadata": {},
   "source": [
    "# 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33385f58-3b83-4631-8c98-2e1dd82129af",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d24a58f2-56e0-4ef6-af84-6787d16afa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.zeros_like(y, dtype=np.float64)  # Инициализация начальных предсказаний\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - y_pred  # Ошибка\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)  # Обновляем предсказания\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0], dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "112b9bf3-b2a3-4c24-a76f-f17fe5eb5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, n_classes=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.n_classes = n_classes\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Определяем количество классов из y\n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        y_pred = np.zeros_like(y, dtype=np.float64)  # Инициализация начальных предсказаний\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - self.sigmoid(y_pred)  # Ошибка\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)  # Обновляем предсказания\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0], dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return (self.sigmoid(y_pred) > 0.5).astype(int)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Получаем вероятности для многоклассовой классификации\n",
    "        y_pred = np.zeros((X.shape[0], self.n_classes), dtype=np.float64)  # Создаем массив для вероятностей\n",
    "        for tree in self.trees:\n",
    "            tree_pred = tree.predict(X).reshape(-1, 1)  # Делаем предсказания для каждого дерева\n",
    "            y_pred += self.learning_rate * tree_pred  # Добавляем их к общей вероятности\n",
    "        \n",
    "        # Применяем softmax для многоклассовой классификации\n",
    "        return self.softmax(y_pred)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Стабилизация exp для предотвращения переполнения\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)  # Нормализация вероятностей для всех классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c8e4e-d7df-48ad-9477-7b6c8283b367",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c208d4-4dcf-4c4b-bdc0-494e4e9a25d1",
   "metadata": {},
   "source": [
    "### Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2dd5eff-0bc0-4ec2-8c88-58d95a6c5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для классификации\n",
    "model_class = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model_class.fit(X_class_improved_scaled, y_class_improved)\n",
    "y_pred_class_impl = model_class.predict(X_class_improved_scaled)\n",
    "\n",
    "# Для регрессии\n",
    "model_reg = GradientBoosting(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model_reg.fit(X_reg_improved_scaled, y_reg_improved)\n",
    "y_pred_reg_impl = model_reg.predict(X_reg_improved_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5270add-8706-4f0d-9999-89be85f64e1a",
   "metadata": {},
   "source": [
    "## c. Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4818dea-c9b6-47aa-8d03-09c96ee7872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество классификации (имплементированная модель):\n",
      "Accuracy: 0.5913\n",
      "F1-Score: 0.2777\n",
      "ROC-AUC: 0.5000\n",
      "\n",
      "Качество регрессии (имплементированная модель):\n",
      "MSE: 215740117.6078\n",
      "MAE: 10847.6789\n",
      "R²: 0.9658\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества классификации\n",
    "accuracy_class_impl = accuracy_score(y_class_improved, y_pred_class_impl)\n",
    "f1_class_impl = f1_score(y_class_improved, y_pred_class_impl, average='macro')\n",
    "\n",
    "# Для многоклассовой классификации: предсказание вероятностей\n",
    "y_pred_proba_class_impl = model_class.predict_proba(X_class_improved_scaled)\n",
    "\n",
    "# Оценка ROC-AUC для многоклассовой классификации\n",
    "roc_auc_class_impl = roc_auc_score(y_class_improved, y_pred_proba_class_impl, multi_class='ovr')\n",
    "\n",
    "# Оценка качества регрессии\n",
    "mse_reg_impl = mean_squared_error(y_reg_improved, y_pred_reg_impl)\n",
    "mae_reg_impl = mean_absolute_error(y_reg_improved, y_pred_reg_impl)\n",
    "r2_reg_impl = r2_score(y_reg_improved, y_pred_reg_impl)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Качество классификации (имплементированная модель):\")\n",
    "print(f\"Accuracy: {accuracy_class_impl:.4f}\")\n",
    "print(f\"F1-Score: {f1_class_impl:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_class_impl:.4f}\")\n",
    "\n",
    "print(\"\\nКачество регрессии (имплементированная модель):\")\n",
    "print(f\"MSE: {mse_reg_impl:.4f}\")\n",
    "print(f\"MAE: {mae_reg_impl:.4f}\")\n",
    "print(f\"R²: {r2_reg_impl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa193aa-3b88-4101-99f5-8bba5128e082",
   "metadata": {},
   "source": [
    "## d. Сравнение с результатами из пункта 2\n",
    "\n",
    "Для начала, давайте сравним результаты, полученные с помощью имплементированного алгоритма градиентного бустинга, с результатами, полученными в пункте 2, где использовались стандартные методы классификации и регрессии (например, sklearn).\n",
    "\n",
    "Качество классификации:\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "Имплементированная модель: 0.5913\n",
    "Стандартная модель (например, с использованием sklearn): Показатель может варьироваться в зависимости от использованного алгоритма, но в целом ожидаемая точность для базовых моделей градиентного бустинга часто лежит в пределах 0.6-0.8.\n",
    "Сравнение показывает, что наша модель показывает умеренную точность, но она не достигла выдающихся результатов.\n",
    "F1-Score:\n",
    "\n",
    "Имплементированная модель: 0.2777\n",
    "Стандартная модель: F1-Score может быть значительно выше в более сильных моделях (например, в XGBoost или других продвинутых вариантах градиентного бустинга).\n",
    "Результат в 0.2777 указывает на слабую способность модели обрабатывать дисбаланс классов или другие проблемы в данных, что требует улучшения.\n",
    "ROC-AUC:\n",
    "\n",
    "Имплементированная модель: 0.5000\n",
    "Стандартная модель: ROC-AUC для хорошей модели обычно выше 0.7 или даже 0.8, особенно для многоклассовых задач.\n",
    "Результат 0.5000 близок к случайному классификатору, что указывает на проблемы с моделированием или выбором параметров, которые могут быть улучшены.\n",
    "\n",
    "Качество регрессии:\n",
    "\n",
    "MSE (Mean Squared Error):\n",
    "\n",
    "Имплементированная модель: 215740117.6078\n",
    "Стандартная модель: В случае успешной модели, MSE обычно значительно ниже (в зависимости от масштаба данных).\n",
    "Этот показатель указывает на наличие значительных ошибок предсказания, что требует внимательного анализа для улучшения качества модели.\n",
    "\n",
    "MAE (Mean Absolute Error):\n",
    "\n",
    "Имплементированная модель: 10847.6789\n",
    "Стандартная модель: MAE также может быть значительно ниже в случае хорошей модели.\n",
    "Высокий MAE свидетельствует о том, что модель иногда ошибается на достаточно большие величины.\n",
    "\n",
    "R² (коэффициент детерминации):\n",
    "\n",
    "Имплементированная модель: 0.9658\n",
    "Стандартная модель: В большинстве случаев хороший регрессор достигает R² близкого к 1, но модели с большими ошибками могут показывать значения ниже 0.8.\n",
    "Высокий R² (0.9658) говорит о том, что модель в целом хорошо захватывает тренды в данных, несмотря на высокие ошибки в некоторых точках.\n",
    "\n",
    "## e. Выводы\n",
    "Качество классификации:\n",
    "\n",
    "Имплементированная модель градиентного бустинга показала умеренные результаты, с низким F1-Score и ROC-AUC, что может указывать на проблемы с оптимизацией модели или неправильным выбором гиперпараметров.\n",
    "Для улучшения классификации стоит:\n",
    "Проанализировать данные на наличие дисбаланса классов и применить техники для его устранения (например, с использованием взвешенных классов или over-sampling/under-sampling).\n",
    "Рассмотреть более сложные алгоритмы (например, XGBoost или LightGBM), которые могут показать лучшие результаты.\n",
    "Оптимизировать гиперпараметры модели для повышения точности и стабильности предсказаний.\n",
    "\n",
    "Качество регрессии:\n",
    "\n",
    "Имплементированная модель имеет очень высокий R², что говорит о том, что она в целом хорошо объясняет вариации в данных. Однако, высокие значения MSE и MAE указывают на значительные отклонения в некоторых предсказаниях.\n",
    "Для улучшения регрессии следует:\n",
    "Проанализировать модель на наличие выбросов, которые могут существенно увеличивать ошибку.\n",
    "Рассмотреть возможность использования регуляризации или других методов для уменьшения ошибок на отдельных примерах.\n",
    "Попробовать применить методы, такие как бустинг с деревьями (например, XGBoost), для получения более точных предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c203b-98be-4ad9-a33a-6b7c21a52a3f",
   "metadata": {},
   "source": [
    "## f,g.\tДобавление техники из улучшенного бейзлайна (пункт 3с)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ece224f0-c7a7-4797-ba04-2c9ff642a83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество классификации (с улучшениями):\n",
      "Accuracy: 0.5359\n",
      "F1-Score: 0.2518\n",
      "ROC-AUC: 0.5000\n",
      "\n",
      "Качество регрессии (с улучшениями):\n",
      "MSE: 396573370.0798\n",
      "MAE: 14512.2126\n",
      "R²: 0.9371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.zeros_like(y, dtype=np.float64)  # Инициализация начальных предсказаний\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - y_pred  # Ошибка\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)  # Обновляем предсказания\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0], dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "class GradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, n_classes=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.n_classes = n_classes\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Определяем количество классов из y\n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        y_pred = np.zeros_like(y, dtype=np.float64)  # Инициализация начальных предсказаний\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - self.sigmoid(y_pred)  # Ошибка\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)  # Обновляем предсказания\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0], dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return (self.sigmoid(y_pred) > 0.5).astype(int)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Получаем вероятности для многоклассовой классификации\n",
    "        y_pred = np.zeros((X.shape[0], self.n_classes), dtype=np.float64)  # Создаем массив для вероятностей\n",
    "        for tree in self.trees:\n",
    "            tree_pred = tree.predict(X).reshape(-1, 1)  # Делаем предсказания для каждого дерева\n",
    "            y_pred += self.learning_rate * tree_pred  # Добавляем их к общей вероятности\n",
    "        \n",
    "        # Применяем softmax для многоклассовой классификации\n",
    "        return self.softmax(y_pred)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Стабилизация exp для предотвращения переполнения\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)  # Нормализация вероятностей для всех классов\n",
    "\n",
    "# f. Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Масштабирование для данных классификации\n",
    "X_class_improved_scaled = scaler.fit_transform(X_class_improved)\n",
    "\n",
    "# Масштабирование для данных регрессии\n",
    "X_reg_improved_scaled = scaler.fit_transform(X_reg_improved)\n",
    "\n",
    "# g. Выбор признаков с помощью модели (например, RandomForest для классификации)\n",
    "# Создаем случайный лес для оценки важности признаков только для классификации\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X_class_improved_scaled, y_class_improved)\n",
    "\n",
    "# Выбор признаков с использованием SelectFromModel для классификации\n",
    "selector_class = SelectFromModel(rf_classifier, threshold=\"mean\", max_features=10)\n",
    "X_class_improved_selected = selector_class.transform(X_class_improved_scaled)\n",
    "\n",
    "# Для данных регрессии: используем RandomForestRegressor для выбора признаков\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100)\n",
    "rf_regressor.fit(X_reg_improved_scaled, y_reg_improved)\n",
    "\n",
    "# Выбор признаков для регрессии\n",
    "selector_reg = SelectFromModel(rf_regressor, threshold=\"mean\", max_features=10)\n",
    "X_reg_improved_selected = selector_reg.transform(X_reg_improved_scaled)\n",
    "\n",
    "# Для классификации\n",
    "model_class = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model_class.fit(X_class_improved_selected, y_class_improved)  # Обучаем на выбранных признаках\n",
    "y_pred_class_impl = model_class.predict(X_class_improved_selected)\n",
    "\n",
    "# Для регрессии\n",
    "model_reg = GradientBoosting(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model_reg.fit(X_reg_improved_selected, y_reg_improved)  # Обучаем на выбранных признаках\n",
    "y_pred_reg_impl = model_reg.predict(X_reg_improved_selected)\n",
    "\n",
    "# Оценка качества классификации\n",
    "accuracy_class_impl = accuracy_score(y_class_improved, y_pred_class_impl)\n",
    "f1_class_impl = f1_score(y_class_improved, y_pred_class_impl, average='macro')\n",
    "\n",
    "# Для многоклассовой классификации: предсказание вероятностей\n",
    "y_pred_proba_class_impl = model_class.predict_proba(X_class_improved_selected)\n",
    "\n",
    "# Оценка ROC-AUC для многоклассовой классификации\n",
    "roc_auc_class_impl = roc_auc_score(y_class_improved, y_pred_proba_class_impl, multi_class='ovr')\n",
    "\n",
    "# Оценка качества регрессии\n",
    "mse_reg_impl = mean_squared_error(y_reg_improved, y_pred_reg_impl)\n",
    "mae_reg_impl = mean_absolute_error(y_reg_improved, y_pred_reg_impl)\n",
    "r2_reg_impl = r2_score(y_reg_improved, y_pred_reg_impl)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Качество классификации (с улучшениями):\")\n",
    "print(f\"Accuracy: {accuracy_class_impl:.4f}\")\n",
    "print(f\"F1-Score: {f1_class_impl:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_class_impl:.4f}\")\n",
    "\n",
    "print(\"\\nКачество регрессии (с улучшениями):\")\n",
    "print(f\"MSE: {mse_reg_impl:.4f}\")\n",
    "print(f\"MAE: {mae_reg_impl:.4f}\")\n",
    "print(f\"R²: {r2_reg_impl:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a94b-31b6-4f62-9677-312ce03d6778",
   "metadata": {},
   "source": [
    "## i. Сравнение с результатами базового уровня\n",
    "\n",
    "Качество классификации с улучшениями значительно хуже, чем на базовом уровне. Уровень точности (accuracy) и F1-Score для улучшенной модели существенно ниже, а ROC-AUC падает до 0.5, что указывает на модель, которая классифицирует случайным образом. На базовом уровне модель показывает отличные результаты, что указывает на то, что текущие улучшения (например, отбор признаков или использование другой модели) не способствовали улучшению качества классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e029955-ce0e-4863-9fd4-574b14537b6f",
   "metadata": {},
   "source": [
    "## j. Выводы:\n",
    "\n",
    "Для классификации улучшенная модель значительно уступает базовой. Это может быть связано с неудачным выбором моделей или методов улучшения, которые не оказались эффективными для данной задачи. Вероятно, стоит пересмотреть выбранные методы улучшения или настроить параметры модели для достижения лучших результатов.\n",
    "\n",
    "Для регрессии улучшенная модель показывает хорошие результаты в плане R², однако ошибки MSE и MAE значительно выше, чем на базовом уровне. Это может означать, что улучшенная модель хотя и сохраняет общую способность к прогнозированию, но её предсказания становятся менее точными по сравнению с базовой моделью.\n",
    "\n",
    "В целом, несмотря на усилия по улучшению моделей, они пока не привели к значительному улучшению по сравнению с базовыми показателями. Следует рассмотреть более глубокую настройку моделей или выбор других методов улучшений, таких как тюнинг гиперпараметров, добавление новых признаков или применение других техник обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aae81-d917-45ed-ab03-2d5d58230cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
