{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875271c8-4e8c-4592-8b38-92962614a21c",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3 (Проведение исследований с решающим деревом)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c9126-09bc-4f5a-83ea-31cf14f12e00",
   "metadata": {},
   "source": [
    "# 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd96de-25a2-4bfb-945d-04c76914d45f",
   "metadata": {},
   "source": [
    "## a. Набор данных для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6129-a09e-4e28-a44d-7c65df4b3e23",
   "metadata": {},
   "source": [
    "**Датасет:** \"Heart Disease UCI\"\n",
    "\n",
    "**Источник:** Kaggle - Heart Disease UCI Datas https://www.kaggle.com/datasets/redwankarimsony/heart-disease-dataet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 14 характеристик пациентов (например, возраст, пол, уровень холестерина, результаты электрокардиографии и т. д.) и метку, указывающую наличие или отсутствие сердечного заболева\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Проблема сердечно-сосудистых заболеваний является одной из самых серьезных в медицине, и разработка моделей, которые могут помочь в ранней диагностике, имеет высокую практическую ценность.\n",
    "\n",
    "2. **Разнообразие данных:**  \n",
    "   Датасет содержит числовые и категориальные признаки, что позволяет продемонстрировать работу алгоритма с различными типами данных.\n",
    "\n",
    "3. **Классификация:**  \n",
    "   Основная цель — предсказать вероятность наличия заболевания на основе входных данных, что является задачей бинарной классификации.ации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ac49f-1d3d-40ca-b8eb-a66a59359d88",
   "metadata": {},
   "source": [
    "## b. Набор данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c548a5-2e95-4fd9-9031-9e47e6bda61b",
   "metadata": {},
   "source": [
    "**Датасет:** \"House Prices - Advanced Regression Techniques\"\n",
    "\n",
    "**Источник:** Kaggle - House Prices Datas https://www.kaggle.com/datasets/lespin/house-prices-datasetet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 79 характеристик жилых  США), включая площадь, количество комнат, год постройки дома.\n",
    "\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Прогнозирование стоимости недвижимости является важной задачей для рынка недвижимости и используется агентствами и банками для оценки ценности активов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5683a2-770f-41d9-a997-c3db1ed0dcaa",
   "metadata": {},
   "source": [
    "## Метрики качества и их обоснование\n",
    "\n",
    "### Классификация (Heart Disease UCI)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Accuracy (Точность):**  \n",
    "   Показывает долю верно классифицированных примеров среди всех примеров. Это базовая метрика, которая дает общее представление о производительности модели.\n",
    "\n",
    "2. **F1-score:**  \n",
    "   Среднее гармоническое между Precision и Recall. Эта метрика обоснована тем, что важно сбалансировать количество правильно определенных положительных и отрицательных примеров, особенно в задачах с несбалансированными классами.\n",
    "\n",
    "3. **ROC-AUC:**  \n",
    "   Показывает способность модели различать классы. Эта метрика важна при работе с задачами, где критично улавливать отношения между вероятностью и реальной принадлежностью к классу, что позволяет оценить качество классификации на различных порогах.\n",
    "\n",
    "## Регрессия (House Prices)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Mean Squared Error (MSE):**  \n",
    "   Среднее квадратичное отклонение между реальными и предсказанными значениями. Эта метрика подходит для оценки ошибок, акцентируя внимание на крупных отклонениях, что может быть полезно в задачах, где важны большие ошибки.\n",
    "\n",
    "2. **Mean Absolute Error (MAE):**  \n",
    "   Среднее абсолютное отклонение. Эта метрика подходит для понимания реальной средней ошибки и более устойчива к выбросам, чем MSE, что делает её полезной в практических приложениях.\n",
    "\n",
    "3. **R² (коэффициент детерминации):**  \n",
    "   Показывает, насколько хорошо модель объясняет изменчивость данных. Высокий R² указывает на то, что модель объясняет большую часть вариации, что является важным показателем её эффективности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f7139-ecfc-4373-b566-5ec6f3aee30c",
   "metadata": {},
   "source": [
    "# 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d7956-a199-4c7e-b497-de82c34116f6",
   "metadata": {},
   "source": [
    "## a. Обучение моделей из scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7ea2a-f379-473a-a174-369a5c96811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a3c03-ee5a-46d4-9805-188093a65983",
   "metadata": {},
   "source": [
    "### Код для классификации (на примере Heart Disease UCI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d66b1f0-3674-4a61-83e7-e5b7b90255e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5543478260869565, 0.37450444793301935, 0.635223504770725)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Загрузка данных\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "df = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Посмотрим на данные\n",
    "df.head()\n",
    "\n",
    "# Преобразуем категориальные признаки в числовые значения с помощью LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Преобразуем все строковые столбцы в числовые\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Предположим, что целевая переменная называется 'num'\n",
    "X = df.drop(columns=['num'])  # Все признаки\n",
    "y = df['num']  # Целевая переменная\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучим модель решающего дерева\n",
    "model_class = DecisionTreeClassifier(random_state=42)\n",
    "model_class.fit(X_train, y_train)\n",
    "\n",
    "# Сделаем предсказания\n",
    "y_pred_class = model_class.predict(X_test)\n",
    "\n",
    "# Оценим качество модели\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "f1 = f1_score(y_test, y_pred_class, average='macro')\n",
    "roc_auc = roc_auc_score(y_test, model_class.predict_proba(X_test), multi_class='ovr', average='macro')\n",
    "\n",
    "accuracy, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8fb08-abfe-4499-b7d2-d3d0784f939d",
   "metadata": {},
   "source": [
    "### Код для регрессии (на примере House Prices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d5f183-fb79-473b-a22b-1fb8f65ef791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501598840.260274, 25726.54794520548, 0.8042327275659711)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "# Загрузка данных\n",
    "df = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "# Посмотрим на данные\n",
    "df.head()\n",
    "\n",
    "# Преобразуем категориальные признаки с помощью One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Разделим данные на признаки и целевую переменную\n",
    "X_reg = df_encoded.drop(columns=['SalePrice'])  # Все признаки\n",
    "y_reg = df['SalePrice']  # Целевая переменная\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучим модель решающего дерева\n",
    "model_reg = DecisionTreeRegressor(random_state=42)\n",
    "model_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Сделаем предсказания\n",
    "y_pred_reg = model_reg.predict(X_test_reg)\n",
    "\n",
    "# Оценим качество модели\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "mse, mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af5944-1069-4696-a4c7-af4244935b1b",
   "metadata": {},
   "source": [
    "## b. Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6a59a-4c22-4ab0-8ff8-c70faf2ce3ae",
   "metadata": {},
   "source": [
    "### Для классификации:\n",
    "Accuracy (Точность): 0.5543 Точность модели составляет 55.43%, что означает, что модель правильно предсказала классы в 55.43% случаев. Это показатель общего числа верных предсказаний по отношению ко всем предсказаниям.\n",
    "\n",
    "F1 Score (Скор F1): 0.3745 F1 Score — это гармоническое среднее между точностью и полнотой. Значение 0.3745 указывает на то, что модель испытывает трудности в балансировке между точностью и полнотой, возможно, из-за неправильной настройки порога или недостаточной сбалансированности классов.\n",
    "\n",
    "ROC AUC (Площадь под кривой ROC): 0.6352 Площадь под кривой ROC равна 0.6352, что указывает на умеренную способность модели различать положительные и отрицательные классы. Значение, близкое к 0.5, говорит о том, что модель не слишком хорошо разделяет классы, но она всё же имеет некоторое предсказательное значение.\n",
    "\n",
    "### Для регрессии:\n",
    "MSE (Среднеквадратическая ошибка): 1,501,598,840.26\n",
    "Среднеквадратическая ошибка (MSE) равна 1.5 миллиарда, что может свидетельствовать о значительных ошибках в предсказаниях, особенно если значения целевой переменной имеют меньший масштаб. Этот показатель указывает на общую ошибку модели при предсказаниях.\n",
    "\n",
    "MAE (Средняя абсолютная ошибка): 25,726.55\n",
    "Средняя абсолютная ошибка (MAE) равна 25,726.55, что означает, что в среднем ошибка предсказания для каждого примера составляет около 25,726 единиц. Это также указывает на возможные крупные отклонения между предсказаниями и реальными значениями.\n",
    "\n",
    "R2 (Коэффициент детерминации): 0.8042\n",
    "Коэффициент детерминации R2 равен 0.8042, что означает, что модель объясняет 80.42% дисперсии целевой переменной. Это относительно хороший результат, указывающий на то, что модель достаточно хорошо подходит для задачи, хотя есть ещё возможности для улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456cf71-d85b-4efc-893b-dbd9b337536c",
   "metadata": {},
   "source": [
    "# 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175f77a-11be-4892-80f8-243dacc0dda3",
   "metadata": {},
   "source": [
    "## a. Формулировка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a7f8c-98f4-4c2d-be5f-179e42d865ff",
   "metadata": {},
   "source": [
    "Для улучшения качества моделей как для классификации, так и для регрессии, можно выдвинуть следующие гипотезы:\n",
    "\n",
    "Препроцессинг данных:\n",
    "\n",
    "Применить стандартизацию или нормализацию признаков для улучшения производительности модели.\n",
    "Преобразовать категориальные переменные в числовые (например, с помощью one-hot encoding или label encoding), если это не было сделано.\n",
    "Применить обработку пропусков данных (например, с использованием медианы или моды для категориальных и числовых признаков).\n",
    "\n",
    "Визуализация данных:\n",
    "\n",
    "Использовать визуализацию зависимостей между признаками и целевой переменной, чтобы выявить важные взаимодействия и зависимости.\n",
    "Для классификации: анализировать распределение классов для выявления несбалансированных классов и применять методы балансировки классов (например, oversampling или undersampling).\n",
    "Для регрессии: анализировать распределение целевой переменной и применить логарифмическое преобразование, если распределение имеет сильное отклонение от нормального.\n",
    "\n",
    "Формирование новых признаков:\n",
    "\n",
    "Попробовать создавать новые признаки, комбинируя существующие, например, путем взаимодействия признаков или выделения временных признаков (если есть временные данные).\n",
    "Для регрессии: логарифмическое преобразование целевой переменной или создание дополнительных признаков, таких как категории по диапазонам.\n",
    "\n",
    "Подбор гиперпараметров на кросс-валидации:\n",
    "\n",
    "Использовать кросс-валидацию для подбора оптимальных гиперпараметров модели (например, максимальная глубина дерева решений или минимальное количество образцов в листе для дерева решений).\n",
    "Применить сеточный или случайный поиск (GridSearchCV или RandomizedSearchCV) для настройки гиперпараметров модели.\n",
    "\n",
    "Использование ансамблевых методов:\n",
    "\n",
    "Применить ансамблевые методы, такие как случайный лес или градиентный бустинг, которые часто показывают лучшие результаты по сравнению с одиночными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246ba8e-7f4a-4f30-afdb-4f83c1d4cf3b",
   "metadata": {},
   "source": [
    "## b. Проверка гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb2042-079a-4646-971f-35b2d256b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161f7df-1bc2-4fdf-bb60-14c866575f64",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи классификации (Heart Disease UCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b36a4fa-5ba6-422f-9979-feb0039e9c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6032608695652174, 0.44984228370313917, 0.836709847002848)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Заполним пропущенные значения с помощью SimpleImputer (среднее для числовых признаков)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)  # Применяем на обучающих данных\n",
    "X_test_imputed = imputer.transform(X_test)  # Применяем на тестовых данных\n",
    "\n",
    "# Применение стандартной нормализации\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train_imputed)  # Используем X_train_imputed после заполнения пропусков\n",
    "\n",
    "# Балансировка классов с помощью SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y_train)\n",
    "\n",
    "# Настройка гиперпараметров для случайного леса\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search_rf.fit(X_res, y_res)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "X_test_scaled = scaler.transform(X_test_imputed)  # Применяем тот же scaler для тестовой выборки\n",
    "y_pred_class_improved = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Оценка качества модели\n",
    "accuracy_improved = accuracy_score(y_test, y_pred_class_improved)\n",
    "f1_improved = f1_score(y_test, y_pred_class_improved, average='macro')\n",
    "roc_auc_improved = roc_auc_score(y_test, best_rf.predict_proba(X_test_scaled), multi_class='ovr', average='macro')\n",
    "\n",
    "accuracy_improved, f1_improved, roc_auc_improved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c5bdc-9dfa-475d-8f60-1f53ad621b93",
   "metadata": {},
   "source": [
    "### Улучшение модели для задачи регрессии (House Prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0e1afa-78c0-44b2-9eea-38013550e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Model Performance:\n",
      "Mean Squared Error: 853962860.89\n",
      "Mean Absolute Error: 17855.40\n",
      "R²: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Применение стандартной нормализации\n",
    "scaler = StandardScaler()\n",
    "X_scaled_reg = scaler.fit_transform(X_train_reg)\n",
    "\n",
    "# Преобразуем в DataFrame, чтобы сохранить имена колонок\n",
    "X_scaled_reg_df = pd.DataFrame(X_scaled_reg, columns=X_train_reg.columns)\n",
    "\n",
    "# Настройка гиперпараметров для случайного леса\n",
    "param_grid_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "grid_search_reg = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_reg, cv=5)\n",
    "grid_search_reg.fit(X_scaled_reg_df, y_train_reg)\n",
    "\n",
    "best_regressor = grid_search_reg.best_estimator_\n",
    "\n",
    "# Преобразуем тестовые данные в DataFrame\n",
    "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
    "X_test_reg_scaled_df = pd.DataFrame(X_test_reg_scaled, columns=X_test_reg.columns)\n",
    "\n",
    "# Сделаем предсказания\n",
    "y_pred_reg_improved = best_regressor.predict(X_test_reg_scaled_df)\n",
    "\n",
    "# Рассчитываем метрики качества модели\n",
    "mse_improved = mean_squared_error(y_test_reg, y_pred_reg_improved)\n",
    "mae_improved = mean_absolute_error(y_test_reg, y_pred_reg_improved)\n",
    "r2_improved = r2_score(y_test_reg, y_pred_reg_improved)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Improved Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse_improved:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_improved:.2f}\")\n",
    "print(f\"R²: {r2_improved:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78c154-b5bd-4c12-a5b4-b9a748a9f6e9",
   "metadata": {},
   "source": [
    "### Оценить качество моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cdf5d-05a1-46f0-9e42-5835a838517e",
   "metadata": {},
   "source": [
    "#### Для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9811dbbd-5a18-4377-9fed-178928c84608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6032608695652174, 0.44984228370313917, 0.836709847002848)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Оценка качества модели на тестовой выборке\n",
    "accuracy_improved = accuracy_score(y_test, y_pred_class_improved)\n",
    "f1_improved = f1_score(y_test, y_pred_class_improved, average='macro')\n",
    "roc_auc_improved = roc_auc_score(y_test, best_rf.predict_proba(X_test_scaled), multi_class='ovr', average='macro')\n",
    "\n",
    "accuracy_improved, f1_improved, roc_auc_improved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95018280-9640-4fcc-8a1c-22715bba43be",
   "metadata": {},
   "source": [
    "#### Для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8c3bb64-f974-49b3-9650-b5a241c77b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853962860.8934977, 17855.4002630477, 0.8886666827685462)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_improved = mean_squared_error(y_test_reg, y_pred_reg_improved)\n",
    "mae_improved = mean_absolute_error(y_test_reg, y_pred_reg_improved)\n",
    "r2_improved = r2_score(y_test_reg, y_pred_reg_improved)\n",
    "\n",
    "mse_improved, mae_improved, r2_improved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede966a-8cba-4e1a-b13f-3ee53ccf5bd0",
   "metadata": {},
   "source": [
    "### Сравнение\n",
    "Теперь сравним результаты моделей с улучшенным бейзлайном (после применения улучшений в виде гиперпараметрической настройки, нормализации данных и использования методов балансировки классов) с результатами моделей из пункта 2 (первоначальные модели без улучшений).\n",
    "\n",
    "Выводы по классификации:\n",
    "\n",
    "Успех улучшений очевиден. Точность модели с улучшениями увеличилась с 0.5543 до 0.6033.\n",
    "F1 Score, который учитывает как точность, так и полноту, также значительно улучшился, с 0.3745 до 0.4498.\n",
    "ROC AUC значительно повысился с 0.6352 до 0.8367, что говорит о большем качестве предсказаний модели и лучшей способности различать классы.\n",
    "\n",
    "Для регрессии:\n",
    "\n",
    "Выводы по регрессии:\n",
    "\n",
    "MSE (среднеквадратичная ошибка) снизилась с 1501598840.26 до 853962860.89, что свидетельствует об улучшении точности предсказаний модели.\n",
    "MAE (средняя абсолютная ошибка) также снизилась с 25726.55 до 17855.40.\n",
    "R2 улучшился с 0.8042 до 0.8887, что говорит о значительном улучшении объясняемой дисперсии и более высокой предсказательной способности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459216-bab9-4c17-b54a-a74f46027ad0",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "На основе проведенного сравнения можно сделать следующие выводы:\n",
    "\n",
    "Для классификации:\n",
    "\n",
    "Улучшение бейзлайна значительно повысило точность модели. Применение нормализации признаков, балансировки классов и настройки гиперпараметров способствовало значительному улучшению модели.\n",
    "ROC AUC и F1 Score также улучшились, что подтверждает, что модель стала лучше различать классы и более эффективно учитывать оба аспекта — точность и полноту.\n",
    "\n",
    "Для регрессии:\n",
    "\n",
    "Улучшения, включающие нормализацию признаков и настройку гиперпараметров модели, существенно снизили ошибку (как MSE, так и MAE) и улучшили значение R2, что говорит о более точных предсказаниях и лучшем соответствии модели данным.\n",
    "Таким образом, улучшения, предложенные на этапе гипотез, действительно дали значительное улучшение качества моделей как для задачи классификации, так и для задачи регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447afc47-e890-4433-9942-558fe1182bca",
   "metadata": {},
   "source": [
    "# 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33385f58-3b83-4631-8c98-2e1dd82129af",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68a833-679b-4f45-b053-75b9aec0d1d7",
   "metadata": {},
   "source": [
    "### Классификация: Реализация алгоритма дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2eb955d-f346-4585-8af8-fb64a633a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.classes_ = None  # Для хранения уникальных классов\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "        self.classes_ = np.unique(y)  # Сохраняем уникальные классы\n",
    "        self.class_to_index = {class_label: i for i, class_label in enumerate(self.classes_)}  # Словарь для маппинга классов\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        \n",
    "        if len(unique_classes) == 1:\n",
    "            return {'class': unique_classes[0], 'class_counts': np.bincount(y, minlength=len(self.classes_))}\n",
    "        \n",
    "        if self.max_depth and depth >= self.max_depth:\n",
    "            return {'class': np.bincount(y).argmax(), 'class_counts': np.bincount(y, minlength=len(self.classes_))}\n",
    "        \n",
    "        best_split = self._find_best_split(X, y)\n",
    "        \n",
    "        if best_split is None:\n",
    "            return {'class': np.bincount(y).argmax(), 'class_counts': np.bincount(y, minlength=len(self.classes_))}\n",
    "        \n",
    "        left_tree = self._build_tree(X[best_split['left_indices']], y[best_split['left_indices']], depth + 1)\n",
    "        right_tree = self._build_tree(X[best_split['right_indices']], y[best_split['right_indices']], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature_index': best_split['feature_index'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree,\n",
    "            'class_counts': np.bincount(y, minlength=len(self.classes_))\n",
    "        }\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_gini = float('inf')\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                \n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gini = self._calculate_gini(y[left_indices], y[right_indices])\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = {\n",
    "                        'feature_index': feature_index,\n",
    "                        'threshold': threshold,\n",
    "                        'left_indices': left_indices,\n",
    "                        'right_indices': right_indices\n",
    "                    }\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def _calculate_gini(self, left, right):\n",
    "        left_size = len(left)\n",
    "        right_size = len(right)\n",
    "        total_size = left_size + right_size\n",
    "        \n",
    "        left_gini = 1.0 - sum([(np.sum(left == label) / left_size) ** 2 for label in np.unique(left)])\n",
    "        right_gini = 1.0 - sum([(np.sum(right == label) / right_size) ** 2 for label in np.unique(right)])\n",
    "        \n",
    "        return (left_size / total_size) * left_gini + (right_size / total_size) * right_gini\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.values\n",
    "        predictions = [self._predict_single(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        node = self.tree\n",
    "        while 'class' not in node:\n",
    "            if x[node['feature_index']] <= node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        return node['class']\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = X.values\n",
    "        probas = []\n",
    "        \n",
    "        for x in X:\n",
    "            proba = self._predict_proba_single(x)\n",
    "            probas.append(proba)\n",
    "        \n",
    "        return np.array(probas)\n",
    "\n",
    "    def _predict_proba_single(self, x):\n",
    "        node = self.tree\n",
    "        while 'class' not in node:\n",
    "            if x[node['feature_index']] <= node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        \n",
    "        # Теперь индексы классов безопасно используются благодаря словарю\n",
    "        total_samples = np.sum(node['class_counts'])\n",
    "        proba = np.zeros(len(self.classes_))  # Создаём массив для всех классов\n",
    "        for class_label, count in zip(self.classes_, node['class_counts']):\n",
    "            index = self.class_to_index[class_label]  # Получаем индекс для класса\n",
    "            proba[index] = count / total_samples\n",
    "        \n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2d65e-b528-404f-b867-c4d1fcd94b4a",
   "metadata": {},
   "source": [
    "### Регрессия: Реализация алгоритма линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112b9bf3-b2a3-4c24-a76f-f17fe5eb5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.theta = np.zeros(n_features)\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            predictions = self.predict(X)\n",
    "            gradients = (1 / n_samples) * X.T.dot(predictions - y)\n",
    "            self.theta -= self.learning_rate * gradients\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c8e4e-d7df-48ad-9477-7b6c8283b367",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c208d4-4dcf-4c4b-bdc0-494e4e9a25d1",
   "metadata": {},
   "source": [
    "### Обучение модели классификации (дерево решений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2dd5eff-0bc0-4ec2-8c88-58d95a6c5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение дерева решений\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b8adc-4b1c-4f68-8011-7ca68064d345",
   "metadata": {},
   "source": [
    "### Обучение модели регрессии (линейная регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5237ceba-deae-4ab4-8570-f45ed2ee4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение линейной регрессии\n",
    "regressor = LinearRegression(learning_rate=0.01, epochs=1000)\n",
    "regressor.fit(X_train_reg, y_train_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5270add-8706-4f0d-9999-89be85f64e1a",
   "metadata": {},
   "source": [
    "## c. Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4818dea-c9b6-47aa-8d03-09c96ee7872a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21739130434782608, 0.2464774310896728, 0.5736431144627095)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Предсказания модели на тестовой выборке\n",
    "y_pred_class = clf.predict(X_test)\n",
    "\n",
    "# Оценка точности, F1-метрики\n",
    "accuracy_class = accuracy_score(y_test, y_pred_class)\n",
    "f1_class = f1_score(y_test, y_pred_class, average='weighted')\n",
    "\n",
    "# Для многоклассовой классификации (если больше двух классов)\n",
    "roc_auc_class = roc_auc_score(y_test, clf.predict_proba(X_test), average='macro', multi_class='ovr')\n",
    "\n",
    "# Выводим результаты\n",
    "accuracy_class, f1_class, roc_auc_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8084e7ff-dc79-4e66-b721-2ab2c7a486cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in y_pred_reg: 292\n",
      "NaN in y_test_reg: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39654004435.98972, 178839.81164383562, -4.169793743430856)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Убедимся, что y_pred_reg имеет числовой тип\n",
    "y_pred_reg = np.array(y_pred_reg, dtype=np.float64)\n",
    "\n",
    "# Проверяем, есть ли NaN в y_pred_reg\n",
    "print(f\"NaN in y_pred_reg: {np.isnan(y_pred_reg).sum()}\")\n",
    "\n",
    "# Если в y_pred_reg есть NaN, заменим их на 0 (или на другие значения, например медиану)\n",
    "y_pred_reg = np.nan_to_num(y_pred_reg)\n",
    "\n",
    "# Убедимся, что y_test_reg тоже не содержит NaN\n",
    "print(f\"NaN in y_test_reg: {np.isnan(y_test_reg).sum()}\")\n",
    "y_test_reg = np.nan_to_num(y_test_reg)\n",
    "\n",
    "# После этого можно вычислить метрики\n",
    "mse_reg = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_reg = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_reg = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "mse_reg, mae_reg, r2_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa193aa-3b88-4101-99f5-8bba5128e082",
   "metadata": {},
   "source": [
    "## d. Сравнение с результатами из пункта 2\n",
    "\n",
    "На данном этапе сравним метрики для имплементированных вручную алгоритмов с результатами из пункта 2.\n",
    "\n",
    "Выводы для классификации:\n",
    "\n",
    "Имплементированное вручную дерево решений показывает значительно худшие результаты по всем метрикам.\n",
    "Это может быть связано с упрощениями алгоритма (например, отсутствием критерия остановки по количеству объектов в листе) или недостаточно оптимизированной реализацией.\n",
    "\n",
    "Выводы для регрессии:\n",
    "\n",
    "Имплементированная линейная регрессия работает значительно хуже:\n",
    "Ошибки (MSE и MAE) увеличились в несколько раз.\n",
    "Коэффициент R2 стал отрицательным, что указывает на то, что модель хуже среднего предсказания.\n",
    "Причины могут заключаться в недостаточном количестве итераций, высокой скорости обучения или неэффективной инициализации весов.\n",
    "\n",
    "## e. Выводы\n",
    "На основе проведенного сравнения и анализа результатов можно сделать следующие выводы:\n",
    "\n",
    "Качество имплементированных моделей:\n",
    "\n",
    "Классификация: Имплементированное вручную дерево решений показало значительно худшие результаты по всем метрикам (точность, F1, ROC AUC).\n",
    "Это указывает на то, что алгоритм либо был реализован с упрощениями, либо требует дополнительной настройки, такой как глубина дерева, минимальное число объектов в листе и критерий разбиения.\n",
    "Регрессия: Имплементированная линейная регрессия также значительно уступила библиотечному варианту.\n",
    "Ошибки выросли на порядок, а R² стал отрицательным, что говорит о неспособности модели объяснить разброс данных.\n",
    "Причины низкой производительности:\n",
    "\n",
    "Упрощенная реализация алгоритмов (например, в дереве решений могли быть упущены важные аспекты, такие как обработка равнозначных разбиений или критерии остановки).\n",
    "Недостаточная оптимизация гиперпараметров, особенно для регрессии (например, скорость обучения или количество итераций).\n",
    "Возможные ошибки в коде или логике реализации.\n",
    "Сравнение с библиотечными моделями:\n",
    "\n",
    "Библиотечные модели из sklearn имеют оптимизированные реализации с продуманными эвристиками, что делает их значительно более эффективными.\n",
    "Имплементированные алгоритмы пока не могут конкурировать с библиотечными аналогами без существенных доработок.\n",
    "Роль улучшенного бейзлайна:\n",
    "\n",
    "Улучшенный бейзлайн из пункта 3 показал значительное улучшение метрик для библиотечных моделей. Это подчеркивает, что качество моделей сильно зависит от качества данных, а не только от самого алгоритма.\n",
    "Будущие шаги:\n",
    "\n",
    "Реализацию алгоритмов можно улучшить за счет добавления критериев остановки, тестирования различных стратегий разбиения (для дерева) и корректной настройки гиперпараметров (для линейной регрессии).\n",
    "Использование техник из улучшенного бейзлайна (например, нормализация данных, обработка категориальных признаков) может улучшить результаты для вручную имплементированных алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c203b-98be-4ad9-a33a-6b7c21a52a3f",
   "metadata": {},
   "source": [
    "## f,g.\tДобавление техники из улучшенного бейзлайна (пункт 3с)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ece224f0-c7a7-4797-ba04-2c9ff642a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # Разделяем признаки на числовые и категориальные\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Пайплайн для числовых признаков\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),  # Заполнение пропусков медианой\n",
    "        ('scaler', StandardScaler())  # Нормализация\n",
    "    ])\n",
    "\n",
    "    # Пайплайн для категориальных признаков\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),  # Заполнение пропусков\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot кодирование\n",
    "    ])\n",
    "\n",
    "    # Объединение пайплайнов\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Преобразование данных\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Отбор признаков (убираем низкую дисперсию)\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    X_processed = selector.fit_transform(X_processed)\n",
    "\n",
    "    return X_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c00654e-8b42-48b7-833d-0c74df974804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ручная имплементация дерева для классификации (упрощённый CART)\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "\n",
    "class ManualDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        # Вычисление показателя Джини\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        impurity = 1 - sum((count / len(y)) ** 2 for count in counts)\n",
    "        return impurity\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        \n",
    "        # Создание словарей для подсчета классов\n",
    "        num_left = {c: 0 for c in unique_classes}\n",
    "        num_right = {c: np.sum(y == c) for c in unique_classes}\n",
    "        \n",
    "        best_gini = float('inf')\n",
    "        best_split = None\n",
    "        best_left = None\n",
    "        best_right = None\n",
    "        best_threshold = None\n",
    "        best_idx = None\n",
    "    \n",
    "        # Проходим по всем признакам\n",
    "        for idx in range(n):\n",
    "            # Получаем все возможные значения для этого признака\n",
    "            thresholds = np.unique(X[:, idx])\n",
    "            for thr in thresholds:\n",
    "                # Делим данные на две группы\n",
    "                left_mask = X[:, idx] < thr\n",
    "                right_mask = ~left_mask\n",
    "    \n",
    "                # Подсчитываем количество объектов для каждого класса в левых и правых поддеревьях\n",
    "                num_left_copy = num_left.copy()\n",
    "                num_right_copy = num_right.copy()\n",
    "    \n",
    "                for i in range(m):\n",
    "                    if left_mask[i]:\n",
    "                        num_left_copy[y[i]] += 1\n",
    "                        num_right_copy[y[i]] -= 1\n",
    "    \n",
    "                # Вычисляем показатель Джини для данного разбиения\n",
    "                gini_left = 1.0 - sum((num_left_copy[c] / sum(left_mask)) ** 2 for c in unique_classes)\n",
    "                gini_right = 1.0 - sum((num_right_copy[c] / sum(right_mask)) ** 2 for c in unique_classes)\n",
    "                gini = (sum(left_mask) * gini_left + sum(right_mask) * gini_right) / m\n",
    "    \n",
    "                # Если текущее разбиение лучше, обновляем\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = (idx, thr)\n",
    "                    best_left = left_mask\n",
    "                    best_right = right_mask\n",
    "    \n",
    "        return best_split\n",
    "\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        # Рекурсивное построение дерева\n",
    "        num_samples_per_class = [np.sum(y == i) for i in np.unique(y)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = {\n",
    "            'predicted_class': predicted_class,\n",
    "            'depth': depth\n",
    "        }\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node['feature_index'] = idx\n",
    "                node['threshold'] = thr\n",
    "                node['left'] = self._build_tree(X_left, y_left, depth + 1)\n",
    "                node['right'] = self._build_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "        return self\n",
    "\n",
    "    def _predict_one(self, inputs, tree):\n",
    "        if 'threshold' in tree:\n",
    "            if inputs[tree['feature_index']] < tree['threshold']:\n",
    "                return self._predict_one(inputs, tree['left'])\n",
    "            else:\n",
    "                return self._predict_one(inputs, tree['right'])\n",
    "        else:\n",
    "            return tree['predicted_class']\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(inputs, self.tree) for inputs in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65643e63-9a5c-48f5-9c6f-67e598b975d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualDecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = np.hstack((X, y[:, np.newaxis]))\n",
    "        self.tree = self._build_tree(data, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _build_tree(self, data, depth):\n",
    "        X, y = data[:, :-1], data[:, -1]\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        if (\n",
    "            num_samples < self.min_samples_split\n",
    "            or (self.max_depth is not None and depth >= self.max_depth)\n",
    "        ):\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_feature, best_threshold, best_mse = None, None, float(\"inf\")\n",
    "        for feature in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                mse, left, right = self._calculate_split(X, y, feature, threshold)\n",
    "                if mse < best_mse:\n",
    "                    best_feature, best_threshold, best_mse = feature, threshold, mse\n",
    "\n",
    "        if best_feature is None:\n",
    "            return np.mean(y)\n",
    "\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        left_child = self._build_tree(data[left_mask], depth + 1)\n",
    "        right_child = self._build_tree(data[right_mask], depth + 1)\n",
    "\n",
    "        return {\n",
    "            \"feature\": best_feature,\n",
    "            \"threshold\": best_threshold,\n",
    "            \"left\": left_child,\n",
    "            \"right\": right_child,\n",
    "        }\n",
    "\n",
    "    def _calculate_split(self, X, y, feature, threshold):\n",
    "        left_mask = X[:, feature] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "            return float(\"inf\"), None, None\n",
    "\n",
    "        left_y, right_y = y[left_mask], y[right_mask]\n",
    "        mse = (\n",
    "            (left_y.size * np.var(left_y) + right_y.size * np.var(right_y))\n",
    "            / y.size\n",
    "        )\n",
    "\n",
    "        return mse, left_y, right_y\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "\n",
    "        feature, threshold = tree[\"feature\"], tree[\"threshold\"]\n",
    "        if x[feature] <= threshold:\n",
    "            return self._predict_single(x, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_single(x, tree[\"right\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb56d9-1701-4324-811f-d4bb2cad3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Преобразуем целевую переменную в числовые индексы классов\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_class_array = label_encoder.fit_transform(y_train_class)\n",
    "y_test_class_array = label_encoder.transform(y_test_class)\n",
    "\n",
    "# Обучаем дерево, передав X и y отдельно\n",
    "manual_tree_class.fit(X_train_class, y_train_class_array)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_class_improved = manual_tree_class.predict(X_test_class)\n",
    "\n",
    "# Оценка качества\n",
    "accuracy_improved_class = accuracy_score(y_test_class_array, y_pred_class_improved)\n",
    "f1_improved_class = f1_score(y_test_class_array, y_pred_class_improved, average='macro')\n",
    "roc_auc_improved_class = roc_auc_score(\n",
    "    y_test_class_array, manual_tree_class.predict_proba(X_test_class), multi_class='ovr', average='macro'\n",
    ")\n",
    "\n",
    "print(\"Классификация (ручное дерево с улучшенным бейзлайном):\", (accuracy_improved_class, f1_improved_class, roc_auc_improved_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61c5e713-a712-48d3-8ff0-0c3801ea124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регрессия (ручное дерево с улучшенным бейзлайном): (1521695006.8944845, 27331.262222764817, 0.8016127390424869)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем y_train_reg в numpy массив и делаем его двумерным\n",
    "y_train_reg_array = np.array(y_train_reg)  # Теперь это одномерный массив\n",
    "\n",
    "# Обучаем модель\n",
    "manual_tree_reg = ManualDecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "# Обучаем дерево, передав X и y отдельно\n",
    "manual_tree_reg.fit(X_train_reg, y_train_reg_array)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_reg_improved = manual_tree_reg.predict(X_test_reg)\n",
    "\n",
    "# Оценка качества\n",
    "mse_improved_reg = mean_squared_error(y_test_reg, y_pred_reg_improved)\n",
    "mae_improved_reg = mean_absolute_error(y_test_reg, y_pred_reg_improved)\n",
    "r2_improved_reg = r2_score(y_test_reg, y_pred_reg_improved)\n",
    "\n",
    "print(\"Регрессия (ручное дерево с улучшенным бейзлайном):\", (mse_improved_reg, mae_improved_reg, r2_improved_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981276ca-4ce4-46a8-bfb5-eebddfe9f4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0762a94b-31b6-4f62-9677-312ce03d6778",
   "metadata": {},
   "source": [
    "## i. Сравнение с результатами базового уровня\n",
    "\n",
    "Теперь мы сравним результаты моделей с добавленными улучшениями из бейзлайна (пункт 3c) с результатами, полученными в пункте 3 для классификации и регрессии.\n",
    "\n",
    "Классификация:\n",
    "Результаты из пункта 3:\n",
    "\n",
    "Точность: 0.554\n",
    "F1: 0.374\n",
    "ROC AUC: 0.635\n",
    "Результаты после добавления улучшений (ручное дерево с улучшенным бейзлайном):\n",
    "\n",
    "Точность: 0.62\n",
    "F1: 0.45\n",
    "ROC AUC: 0.71\n",
    "Выводы:\n",
    "\n",
    "Для классификации после добавления техник из улучшенного бейзлайна, точность, F1 и ROC AUC увеличились. Это подтверждает, что обработка данных, создание новых признаков или другие изменения в улучшенном бейзлайне значительно повысили качество модели.\n",
    "Несмотря на улучшение, модель всё еще имеет значительные возможности для улучшения, что можно связать с особенностями самого алгоритма, такими как максимальная глубина дерева, разбиение на классы и т. д.\n",
    "Регрессия:\n",
    "Результаты из пункта 3:\n",
    "\n",
    "MSE: 1501598840.26\n",
    "MAE: 25726.55\n",
    "R²: 0.804\n",
    "Результаты после добавления улучшений (ручное дерево с улучшенным бейзлайном):\n",
    "\n",
    "MSE: 1521695006.89\n",
    "MAE: 27331.26\n",
    "R²: 0.8016\n",
    "Выводы:\n",
    "\n",
    "Для регрессии, несмотря на добавление улучшений, значения MSE и MAE немного увеличились, что может свидетельствовать о недостаточной настройке гиперпараметров или проблемы с самим деревом решений (например, переобучение).\n",
    "Однако R² остался на примерно том же уровне, что и в пункте 3, и модель по-прежнему хорошо объясняет вариативность данных.\n",
    "Возможно, требуется дополнительная настройка или использование более сложных моделей (например, ансамбли), чтобы улучшить точность предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e029955-ce0e-4863-9fd4-574b14537b6f",
   "metadata": {},
   "source": [
    "## j. Выводы:\n",
    "Классификация:\n",
    "\n",
    "Добавление улучшений на основе бейзлайна привело к значительному улучшению результатов (точность, F1 и ROC AUC). Это подтверждает, что работы с признаками, обработкой данных и настройкой гиперпараметров могут значительно повысить качество классификаторов.\n",
    "Однако дальнейшее улучшение возможно путем настройки гиперпараметров, использования других моделей (например, случайных лесов или градиентного бустинга).\n",
    "\n",
    "Регрессия:\n",
    "\n",
    "В случае регрессии улучшение не показало значительных изменений в метриках MSE и MAE. Однако, модель все еще хорошо работает с R² около 0.8.\n",
    "Переобучение или недостаточная настройка гиперпараметров может объяснять небольшие ухудшения в ошибках. Возможно, использование более сложных методов, таких как градиентный бустинг или случайные леса, поможет улучшить результат.\n",
    "Общие выводы:\n",
    "\n",
    "Внедрение техник из улучшенного бейзлайна позволило достичь заметных улучшений в классификации, но для регрессии результаты остались относительно стабильными. Это указывает на возможность использования других моделей или дополнительных техник для улучшения производительности.\n",
    "В целом, улучшение бейзлайна значительно способствует повышению качества моделей, но дальнейшее совершенствование алгоритмов требует экспериментов с гиперпараметрами и рассмотрения других алгоритмов машинного обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aae81-d917-45ed-ab03-2d5d58230cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
