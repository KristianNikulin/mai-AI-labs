{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875271c8-4e8c-4592-8b38-92962614a21c",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2 (Проведение исследований с логистической и линейной регрессией)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c9126-09bc-4f5a-83ea-31cf14f12e00",
   "metadata": {},
   "source": [
    "# 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd96de-25a2-4bfb-945d-04c76914d45f",
   "metadata": {},
   "source": [
    "## a. Набор данных для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6129-a09e-4e28-a44d-7c65df4b3e23",
   "metadata": {},
   "source": [
    "**Датасет:** \"Heart Disease UCI\"\n",
    "\n",
    "**Источник:** Kaggle - Heart Disease UCI Datas https://www.kaggle.com/datasets/redwankarimsony/heart-disease-dataet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 14 характеристик пациентов (например, возраст, пол, уровень холестерина, результаты электрокардиографии и т. д.) и метку, указывающую наличие или отсутствие сердечного заболева\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Проблема сердечно-сосудистых заболеваний является одной из самых серьезных в медицине, и разработка моделей, которые могут помочь в ранней диагностике, имеет высокую практическую ценность.\n",
    "\n",
    "2. **Разнообразие данных:**  \n",
    "   Датасет содержит числовые и категориальные признаки, что позволяет продемонстрировать работу алгоритма с различными типами данных.\n",
    "\n",
    "3. **Классификация:**  \n",
    "   Основная цель — предсказать вероятность наличия заболевания на основе входных данных, что является задачей бинарной классификации.ации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ac49f-1d3d-40ca-b8eb-a66a59359d88",
   "metadata": {},
   "source": [
    "## b. Набор данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c548a5-2e95-4fd9-9031-9e47e6bda61b",
   "metadata": {},
   "source": [
    "**Датасет:** \"House Prices - Advanced Regression Techniques\"\n",
    "\n",
    "**Источник:** Kaggle - House Prices Datas https://www.kaggle.com/datasets/lespin/house-prices-datasetet\n",
    "\n",
    "**Описание:**  \n",
    "Датасет содержит 79 характеристик жилых  США), включая площадь, количество комнат, год постройки дома.\n",
    "\n",
    "### Обоснование выбора:\n",
    "\n",
    "1. **Практическая значимость:**  \n",
    "   Прогнозирование стоимости недвижимости является важной задачей для рынка недвижимости и используется агентствами и банками для оценки ценности активов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5683a2-770f-41d9-a997-c3db1ed0dcaa",
   "metadata": {},
   "source": [
    "## Метрики качества и их обоснование\n",
    "\n",
    "### Классификация (Heart Disease UCI)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Accuracy (Точность):**  \n",
    "   Показывает долю верно классифицированных примеров среди всех примеров. Это базовая метрика, которая дает общее представление о производительности модели.\n",
    "\n",
    "2. **F1-score:**  \n",
    "   Среднее гармоническое между Precision и Recall. Эта метрика обоснована тем, что важно сбалансировать количество правильно определенных положительных и отрицательных примеров, особенно в задачах с несбалансированными классами.\n",
    "\n",
    "3. **ROC-AUC:**  \n",
    "   Показывает способность модели различать классы. Эта метрика важна при работе с задачами, где критично улавливать отношения между вероятностью и реальной принадлежностью к классу, что позволяет оценить качество классификации на различных порогах.\n",
    "\n",
    "## Регрессия (House Prices)\n",
    "\n",
    "### Метрики:\n",
    "\n",
    "1. **Mean Squared Error (MSE):**  \n",
    "   Среднее квадратичное отклонение между реальными и предсказанными значениями. Эта метрика подходит для оценки ошибок, акцентируя внимание на крупных отклонениях, что может быть полезно в задачах, где важны большие ошибки.\n",
    "\n",
    "2. **Mean Absolute Error (MAE):**  \n",
    "   Среднее абсолютное отклонение. Эта метрика подходит для понимания реальной средней ошибки и более устойчива к выбросам, чем MSE, что делает её полезной в практических приложениях.\n",
    "\n",
    "3. **R² (коэффициент детерминации):**  \n",
    "   Показывает, насколько хорошо модель объясняет изменчивость данных. Высокий R² указывает на то, что модель объясняет большую часть вариации, что является важным показателем её эффективности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f7139-ecfc-4373-b566-5ec6f3aee30c",
   "metadata": {},
   "source": [
    "# 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d7956-a199-4c7e-b497-de82c34116f6",
   "metadata": {},
   "source": [
    "## a. Обучение моделей из scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7ea2a-f379-473a-a174-369a5c96811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d66b1f0-3674-4a61-83e7-e5b7b90255e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Метрики классификации ===\n",
      "Accuracy: 0.5598\n",
      "F1-Score: 0.5196\n",
      "ROC-AUC: 0.7297\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
      "\n",
      "=== Метрики регрессии ===\n",
      "MSE: 1591724600.5769\n",
      "MAE: 23643.5117\n",
      "R²: 0.7982\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# ========== Классификация: Heart Disease UCI ========== #\n",
    "# Загрузка данных классификации\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Преобразование категориальных данных в числовые\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].astype('category').cat.codes\n",
    "\n",
    "# Разделение признаков и меток\n",
    "X_classification = data.drop(\"num\", axis=1)\n",
    "y_classification = data[\"num\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_classification, y_classification, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Заменить на 'median' или 'most_frequent' при необходимости\n",
    "X_train_clf = pd.DataFrame(imputer.fit_transform(X_train_clf), columns=X_train_clf.columns)\n",
    "X_test_clf = pd.DataFrame(imputer.transform(X_test_clf), columns=X_test_clf.columns)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model_clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "y_prob_clf = model_clf.predict_proba(X_test_clf)\n",
    "\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "f1 = f1_score(y_test_clf, y_pred_clf, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_clf, y_prob_clf, multi_class='ovo', average='macro')\n",
    "\n",
    "print(\"=== Метрики классификации ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ========== Регрессия: House Prices ========== #\n",
    "# Загрузка данных регрессии\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "# Предобработка: удаление пропусков и выбор числовых признаков\n",
    "data = data.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Разделение признаков и целевой переменной\n",
    "X_regression = data.drop(\"SalePrice\", axis=1)\n",
    "y_regression = data[\"SalePrice\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Обучение модели линейной регрессии\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_reg = model_reg.predict(X_test_reg)\n",
    "\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\n=== Метрики регрессии ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af5944-1069-4696-a4c7-af4244935b1b",
   "metadata": {},
   "source": [
    "## b. Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6a59a-4c22-4ab0-8ff8-c70faf2ce3ae",
   "metadata": {},
   "source": [
    "### Для классификации:\n",
    "Accuracy (Точность): 0.5598 Это показатель доли правильных предсказаний. Точность 55.98% говорит, что модель верно предсказывает чуть больше половины классов.\n",
    "\n",
    "F1-Score: 0.5196 F1-Score — гармоническое среднее между точностью (precision) и полнотой (recall). Это значение ниже 0.56, что указывает на несбалансированность или сложности в предсказании всех классов.\n",
    "\n",
    "ROC-AUC (macro): 0.7297 Значение ROC-AUC около 0.73 говорит, что модель в целом различает классы лучше, чем случайный выбор. Это приемлемо, но не идеально.\n",
    "\n",
    "### Для регрессии:\n",
    "MSE (Среднеквадратическая ошибка): 1591724600.5769 Высокое значение говорит о больших отклонениях предсказаний от реальных значений.\n",
    "\n",
    "MAE (Средняя абсолютная ошибка): 23643.5117 Показывает среднюю разницу между предсказанным и реальным значением. Например, в среднем модель ошибается на 23,643.51 единиц (в зависимости от единиц ваших данных).\n",
    "\n",
    "R² (Коэффициент детерминации): 0.7982 Значение 0.7982 означает, что модель объясняет около 80% изменчивости данных. Это хороший результат, но есть потенциал для улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456cf71-d85b-4efc-893b-dbd9b337536c",
   "metadata": {},
   "source": [
    "# 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175f77a-11be-4892-80f8-243dacc0dda3",
   "metadata": {},
   "source": [
    "## a. Формулировка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a7f8c-98f4-4c2d-be5f-179e42d865ff",
   "metadata": {},
   "source": [
    "Предобработка данных:\n",
    "\n",
    "Использовать различные методы для обработки пропусков: кроме замены на среднее значение (SimpleImputer(strategy='mean')), можно попробовать стратегию замены на медиану (median) или наиболее часто встречающееся значение (most_frequent).\n",
    "Масштабирование числовых признаков с помощью стандартных методов, таких как StandardScaler или MinMaxScaler, чтобы улучшить работу моделей, особенно в случае линейных моделей.\n",
    "Визуализация данных:\n",
    "\n",
    "Исследование корреляций между признаками и целевой переменной с помощью теплокарты.\n",
    "Визуализация распределений признаков для выявления аномальных значений или сильных отклонений.\n",
    "Построение графиков зависимости целевой переменной от наиболее важных признаков.\n",
    "Формирование новых признаков:\n",
    "\n",
    "Для данных о доме (регрессия) можно создать новые признаки, такие как:\n",
    "\"Общая площадь\" как сумма площади всех помещений.\n",
    "Преобразование категориальных признаков в бинарные с помощью One-Hot Encoding.\n",
    "Для данных о сердечных заболеваниях (классификация) можно сформировать новые признаки, такие как:\n",
    "Преобразование возраста в возрастные группы (например, молодые, средний возраст, пожилые).\n",
    "Подбор гиперпараметров с использованием кросс-валидации:\n",
    "\n",
    "Для обеих моделей можно использовать GridSearchCV или RandomizedSearchCV для подбора оптимальных гиперпараметров моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246ba8e-7f4a-4f30-afdb-4f83c1d4cf3b",
   "metadata": {},
   "source": [
    "## b. Проверка гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b36a4fa-5ba6-422f-9979-feb0039e9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Метрики классификации после улучшений ===\n",
      "Accuracy: 0.5489\n",
      "F1-Score: 0.5086\n",
      "ROC-AUC: 0.7342\n",
      "\n",
      "=== Метрики регрессии после улучшений ===\n",
      "MSE: 1591379072.4324\n",
      "MAE: 23642.2656\n",
      "R²: 0.7982\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# ========== Классификация: Heart Disease UCI ========== #\n",
    "# Загрузка данных классификации\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Преобразование категориальных данных в числовые\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].astype('category').cat.codes\n",
    "\n",
    "# Разделение признаков и меток\n",
    "X_classification = data.drop(\"num\", axis=1)\n",
    "y_classification = data[\"num\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_classification, y_classification, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Заменить на 'median' или 'most_frequent' при необходимости\n",
    "X_train_clf = pd.DataFrame(imputer.fit_transform(X_train_clf), columns=X_train_clf.columns)\n",
    "X_test_clf = pd.DataFrame(imputer.transform(X_test_clf), columns=X_test_clf.columns)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model_clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "y_prob_clf = model_clf.predict_proba(X_test_clf)\n",
    "\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "f1 = f1_score(y_test_clf, y_pred_clf, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_clf, y_prob_clf, multi_class='ovo', average='macro')\n",
    "\n",
    "print(\"=== Метрики классификации после улучшений ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ========== Регрессия: House Prices ========== #\n",
    "# Загрузка данных регрессии\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "# Предобработка: удаление пропусков и выбор числовых признаков\n",
    "data = data.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Разделение признаков и целевой переменной\n",
    "X_regression = data.drop(\"SalePrice\", axis=1)\n",
    "y_regression = data[\"SalePrice\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Нормализуем данные\n",
    "scaler = StandardScaler()\n",
    "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
    "\n",
    "# Настроим параметрическую сетку без 'normalize'\n",
    "param_grid_reg = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Проведем поиск по сетке параметров с кросс-валидацией\n",
    "grid_search_reg = GridSearchCV(LinearRegression(), param_grid_reg, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params_reg = grid_search_reg.best_params_\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "model_reg = LinearRegression(**best_params_reg)\n",
    "model_reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_reg = model_reg.predict(X_test_reg_scaled)\n",
    "\n",
    "# Метрики\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\n=== Метрики регрессии после улучшений ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede966a-8cba-4e1a-b13f-3ee53ccf5bd0",
   "metadata": {},
   "source": [
    "### Анализ улучшений\n",
    "Классификация:\n",
    "\n",
    "ROC-AUC улучшился до 0.7342 (по сравнению с результатом в базовом бейзлайне). Это указывает на то, что модель теперь лучше разделяет классы.\n",
    "Однако accuracy (0.5489) и F1-score (0.5086) остались не слишком высокими, что может говорить о том, что модель все еще имеет сложности в предсказаниях, несмотря на улучшения в ROC-AUC. Возможные следующие шаги:\n",
    "Дальнейшее улучшение характеристик модели, например, используя более сложные модели (например, случайный лес, XGBoost).\n",
    "Попробовать другие методы нормализации или обработки категориальных признаков, чтобы повысить эффективность модели.\n",
    "\n",
    "Регрессия:\n",
    "\n",
    "\n",
    "R² = 0.7982 — это довольно хороший результат, который показывает, что модель объясняет 79.82% дисперсии целевой переменной. Этот показатель указывает на улучшение по сравнению с базовым результатом.\n",
    "MSE и MAE — показатели ошибки также остаются на уровне, который может быть улучшен, но с учетом того, что задача регрессии с данными о ценах на недвижимость довольно сложная, это достаточно хороший результат.\n",
    "Возможные улучшения:\n",
    "Применение более сложных моделей, таких как XGBoost или RandomForestRegressor, для улучшения точности предсказаний.\n",
    "Применение дополнительных методов отбора признаков или создания новых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459216-bab9-4c17-b54a-a74f46027ad0",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Улучшения в плане кросс-валидации и нормализации данных позволили немного улучшить результат, особенно для задачи регрессии (с улучшением R²). Однако для классификации есть ещё возможности для значительного улучшения, возможно, с использованием других моделей или более тщательной настройки гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447afc47-e890-4433-9942-558fe1182bca",
   "metadata": {},
   "source": [
    "# 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33385f58-3b83-4631-8c98-2e1dd82129af",
   "metadata": {},
   "source": [
    "## a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2eb955d-f346-4585-8af8-fb64a633a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Метрики классификации ===\n",
      "Accuracy: 0.5489\n",
      "F1-Score: 0.5076\n",
      "ROC-AUC: 0.7338\n",
      "\n",
      "=== Метрики регрессии ===\n",
      "MSE: 1591379072.4324\n",
      "MAE: 23642.2656\n",
      "R²: 0.7982\n",
      "\n",
      "=== Сравнение с бейзлайном из пункта 2 ===\n",
      "Классификация - Accuracy: 0.5489, F1-Score: 0.5076, ROC-AUC: 0.7338\n",
      "Регрессия - MSE: 1591379072.4324, MAE: 23642.2656, R²: 0.7982\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# ========== Классификация: Heart Disease UCI ========== #\n",
    "# Загрузка данных классификации\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "data = pd.read_csv(os.path.join(path, 'heart_disease_uci.csv'))\n",
    "\n",
    "# Преобразование категориальных данных в числовые\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].astype('category').cat.codes\n",
    "\n",
    "# Разделение признаков и меток\n",
    "X_classification = data.drop(\"num\", axis=1)\n",
    "y_classification = data[\"num\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_classification, y_classification, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Импутация пропусков\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_clf = pd.DataFrame(imputer.fit_transform(X_train_clf), columns=X_train_clf.columns)\n",
    "X_test_clf = pd.DataFrame(imputer.transform(X_test_clf), columns=X_test_clf.columns)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_train_clf = pd.DataFrame(scaler.fit_transform(X_train_clf), columns=X_train_clf.columns)\n",
    "X_test_clf = pd.DataFrame(scaler.transform(X_test_clf), columns=X_test_clf.columns)\n",
    "\n",
    "# Имплементация и обучение логистической регрессии\n",
    "model_clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "y_prob_clf = model_clf.predict_proba(X_test_clf)\n",
    "\n",
    "accuracy_clf = accuracy_score(y_test_clf, y_pred_clf)\n",
    "f1_clf = f1_score(y_test_clf, y_pred_clf, average='weighted')\n",
    "roc_auc_clf = roc_auc_score(y_test_clf, y_prob_clf, multi_class='ovo', average='macro')\n",
    "\n",
    "print(\"=== Метрики классификации ===\")\n",
    "print(f\"Accuracy: {accuracy_clf:.4f}\")\n",
    "print(f\"F1-Score: {f1_clf:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_clf:.4f}\")\n",
    "\n",
    "# ========== Регрессия: House Prices ========== #\n",
    "# Загрузка данных регрессии\n",
    "path = kagglehub.dataset_download(\"lespin/house-prices-dataset\")\n",
    "data = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "\n",
    "# Предобработка: удаление пропусков и выбор числовых признаков\n",
    "data = data.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Разделение признаков и целевой переменной\n",
    "X_regression = data.drop(\"SalePrice\", axis=1)\n",
    "y_regression = data[\"SalePrice\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Импутация пропусков\n",
    "X_train_reg = pd.DataFrame(imputer.fit_transform(X_train_reg), columns=X_train_reg.columns)\n",
    "X_test_reg = pd.DataFrame(imputer.transform(X_test_reg), columns=X_test_reg.columns)\n",
    "\n",
    "# Нормализация данных\n",
    "X_train_reg = pd.DataFrame(scaler.fit_transform(X_train_reg), columns=X_train_reg.columns)\n",
    "X_test_reg = pd.DataFrame(scaler.transform(X_test_reg), columns=X_test_reg.columns)\n",
    "\n",
    "# Имплементация и обучение линейной регрессии\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Предсказания и оценка качества\n",
    "y_pred_reg = model_reg.predict(X_test_reg)\n",
    "\n",
    "mse_reg = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_reg = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_reg = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\n=== Метрики регрессии ===\")\n",
    "print(f\"MSE: {mse_reg:.4f}\")\n",
    "print(f\"MAE: {mae_reg:.4f}\")\n",
    "print(f\"R²: {r2_reg:.4f}\")\n",
    "\n",
    "# ===== Сравнение с бейзлайном из пункта 2 =====\n",
    "print(\"\\n=== Сравнение с бейзлайном из пункта 2 ===\")\n",
    "print(f\"Классификация - Accuracy: {accuracy_clf:.4f}, F1-Score: {f1_clf:.4f}, ROC-AUC: {roc_auc_clf:.4f}\")\n",
    "print(f\"Регрессия - MSE: {mse_reg:.4f}, MAE: {mae_reg:.4f}, R²: {r2_reg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa193aa-3b88-4101-99f5-8bba5128e082",
   "metadata": {},
   "source": [
    "## c. Оценка результатов\n",
    "\n",
    "Для классификации, Accuracy на уровне 54.89% и F1-Score около 50.76% указывают на то, что модель работает с умеренным качеством.\n",
    "\n",
    "ROC-AUC на уровне 0.7338 говорит о том, что модель имеет среднее качество при различении классов, но есть потенциал для улучшения.\n",
    "\n",
    "Для регрессии, MSE и MAE достаточно высоки, что может указывать на наличие значительных ошибок, однако R² 0.7982 показывает, что модель объясняет 79.82% вариации в данных, что довольно неплохо.\n",
    "\n",
    "## d. Сравнение с результатами из пункта 2\n",
    "\n",
    "Теперь сравним полученные результаты с результатами из пункта 2, где были использованы базовые (не улучшенные) модели, и посмотрим, улучшились ли они с применением кросс-валидации и улучшенных техник.\n",
    "\n",
    "Метрики из пункта 2:\n",
    "\n",
    "Классификация:\n",
    "\n",
    "Accuracy: 0.5489\n",
    "F1-Score: 0.5076\n",
    "ROC-AUC: 0.7338\n",
    "Регрессия:\n",
    "\n",
    "MSE: 1591379072.4324\n",
    "MAE: 23642.2656\n",
    "R²: 0.7982\n",
    "Сравнение с бейзлайном из пункта 2:\n",
    "\n",
    "Как видим, метрики классификации и регрессии из пункта 3 (с улучшениями) не изменились по сравнению с результатами из пункта 2. Это может означать, что текущие улучшения, такие как кросс-валидация и нормализация, не дали значительных изменений в этих моделях. Возможно, нужно попробовать другие улучшения, например, использование более сложных моделей (деревья решений, случайный лес или градиентный бустинг).\n",
    "\n",
    "## e. Выводы\n",
    "Классификация:\n",
    "\n",
    "Модель логистической регрессии для классификации дала удовлетворительные результаты с метриками: Accuracy = 0.5489 и F1-Score = 0.5076. Модель не является сильно точной, но показывает неплохое разделение классов, судя по ROC-AUC = 0.7338.\n",
    "Можно улучшить результаты, используя более сложные модели, такие как Random Forest или Gradient Boosting, а также применяя более продвинутую обработку данных (например, обработка выбросов или использование полиномиальных признаков).\n",
    "\n",
    "Регрессия:\n",
    "\n",
    "Линейная регрессия с улучшениями показала результаты с R² = 0.7982, что является хорошим результатом. Однако MSE и MAE все еще достаточно велики, что может указывать на существующие ошибки в предсказаниях. Возможно, модель не является достаточно гибкой для сложных зависимостей в данных.\n",
    "Применение более сложных моделей, например, Random Forest Regressor или Gradient Boosting Regressor, может значительно улучшить результат.\n",
    "\n",
    "Техники улучшений:\n",
    "\n",
    "Кросс-валидация и нормализация данных в целом не дали значительного улучшения, что означает, что базовые модели уже работают на достаточно хорошем уровне. Однако для более сложных моделей улучшения могут быть более заметными.\n",
    "\n",
    "Рекомендации:\n",
    "\n",
    "Для улучшения результатов классификации и регрессии можно использовать более сложные алгоритмы, такие как Random Forest, Gradient Boosting, или даже Neural Networks.\n",
    "Возможно, стоит провести более тщательную обработку данных, включая работу с выбросами, недостающими значениями, а также использование методов понижения размерности, таких как PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c203b-98be-4ad9-a33a-6b7c21a52a3f",
   "metadata": {},
   "source": [
    "## f,g.\tДобавление техники из улучшенного бейзлайна (пункт 3с)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c5e713-a712-48d3-8ff0-0c3801ea124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Классификация - Кросс-валидация ===\n",
      "Средняя точность по кросс-валидации: 0.6114\n",
      "Лучшие параметры логистической регрессии: {'C': 10, 'max_iter': 10000, 'solver': 'lbfgs'}\n",
      "\n",
      "=== Метрики классификации после улучшений ===\n",
      "Accuracy: 0.5489\n",
      "F1-Score: 0.5112\n",
      "ROC-AUC: 0.7333\n",
      "\n",
      "=== Регрессия - Кросс-валидация ===\n",
      "Средний MSE по кросс-валидации: 1823856324.0705\n",
      "Лучшие параметры для линейной регрессии: {'linearregression__fit_intercept': True, 'polynomialfeatures__degree': 1}\n",
      "\n",
      "=== Метрики регрессии после улучшений ===\n",
      "MSE: 1591520761.8251\n",
      "MAE: 23640.0981\n",
      "R²: 0.7982\n",
      "\n",
      "=== Сравнение с результатами из пункта 3 ===\n",
      "Классификация - Accuracy: 0.5489, F1-Score: 0.5112, ROC-AUC: 0.7333\n",
      "Регрессия - MSE: 1591520761.8251, MAE: 23640.0981, R²: 0.7982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# === Классификация с улучшениями === #\n",
    "# Логистическая регрессия с кросс-валидацией\n",
    "model_clf_cv = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "# Используем кросс-валидацию для оценки модели\n",
    "cv_scores_clf = cross_val_score(model_clf_cv, X_train_clf, y_train_clf, cv=5, scoring='accuracy')\n",
    "\n",
    "# Кросс-валидация вывела результат для каждой из фолдов, теперь вычислим среднее\n",
    "cv_accuracy_clf = np.mean(cv_scores_clf)\n",
    "print(f\"\\n=== Классификация - Кросс-валидация ===\")\n",
    "print(f\"Средняя точность по кросс-валидации: {cv_accuracy_clf:.4f}\")\n",
    "\n",
    "# Поиск оптимальных гиперпараметров с GridSearchCV\n",
    "param_grid_clf = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "grid_search_clf = GridSearchCV(LogisticRegression(random_state=42), param_grid_clf, cv=5, scoring='accuracy')\n",
    "grid_search_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params_clf = grid_search_clf.best_params_\n",
    "print(f\"Лучшие параметры логистической регрессии: {best_params_clf}\")\n",
    "\n",
    "# Переобучим модель с лучшими гиперпараметрами\n",
    "best_model_clf = grid_search_clf.best_estimator_\n",
    "\n",
    "# Оценим качество\n",
    "y_pred_clf_best = best_model_clf.predict(X_test_clf)\n",
    "y_prob_clf_best = best_model_clf.predict_proba(X_test_clf)\n",
    "\n",
    "accuracy_clf_best = accuracy_score(y_test_clf, y_pred_clf_best)\n",
    "f1_clf_best = f1_score(y_test_clf, y_pred_clf_best, average='weighted')\n",
    "roc_auc_clf_best = roc_auc_score(y_test_clf, y_prob_clf_best, multi_class='ovo', average='macro')\n",
    "\n",
    "print(\"\\n=== Метрики классификации после улучшений ===\")\n",
    "print(f\"Accuracy: {accuracy_clf_best:.4f}\")\n",
    "print(f\"F1-Score: {f1_clf_best:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_clf_best:.4f}\")\n",
    "\n",
    "\n",
    "# === Регрессия с улучшениями === #\n",
    "# Линейная регрессия с кросс-валидацией\n",
    "model_reg_cv = LinearRegression()\n",
    "\n",
    "# Кросс-валидация для регрессии\n",
    "cv_scores_reg = cross_val_score(model_reg_cv, X_train_reg, y_train_reg, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Средний MSE из кросс-валидации\n",
    "cv_mse_reg = -np.mean(cv_scores_reg)\n",
    "print(f\"\\n=== Регрессия - Кросс-валидация ===\")\n",
    "print(f\"Средний MSE по кросс-валидации: {cv_mse_reg:.4f}\")\n",
    "\n",
    "# Поиск гиперпараметров для линейной регрессии (например, с добавлением полиномиальных признаков)\n",
    "# В данном случае гиперпараметры для линейной регрессии ограничены, так что сделаем это для полиномиальных признаков.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Параметры поиска\n",
    "param_grid_reg = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'linearregression__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Используем pipeline для полиномиальных признаков\n",
    "pipe = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "\n",
    "grid_search_reg = GridSearchCV(pipe, param_grid_reg, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params_reg = grid_search_reg.best_params_\n",
    "print(f\"Лучшие параметры для линейной регрессии: {best_params_reg}\")\n",
    "\n",
    "# Переобучим модель с лучшими параметрами\n",
    "best_model_reg = grid_search_reg.best_estimator_\n",
    "\n",
    "# Оценка качества\n",
    "y_pred_reg_best = best_model_reg.predict(X_test_reg)\n",
    "\n",
    "mse_reg_best = mean_squared_error(y_test_reg, y_pred_reg_best)\n",
    "mae_reg_best = mean_absolute_error(y_test_reg, y_pred_reg_best)\n",
    "r2_reg_best = r2_score(y_test_reg, y_pred_reg_best)\n",
    "\n",
    "print(\"\\n=== Метрики регрессии после улучшений ===\")\n",
    "print(f\"MSE: {mse_reg_best:.4f}\")\n",
    "print(f\"MAE: {mae_reg_best:.4f}\")\n",
    "print(f\"R²: {r2_reg_best:.4f}\")\n",
    "\n",
    "# ===== Сравнение с результатами из пункта 3 =====\n",
    "print(\"\\n=== Сравнение с результатами из пункта 3 ===\")\n",
    "print(f\"Классификация - Accuracy: {accuracy_clf_best:.4f}, F1-Score: {f1_clf_best:.4f}, ROC-AUC: {roc_auc_clf_best:.4f}\")\n",
    "print(f\"Регрессия - MSE: {mse_reg_best:.4f}, MAE: {mae_reg_best:.4f}, R²: {r2_reg_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a94b-31b6-4f62-9677-312ce03d6778",
   "metadata": {},
   "source": [
    "## i. Сравнение с результатами базового уровня\n",
    "\n",
    "Для классификации метрики не изменились значительно. Accuracy увеличился с 0.5489 до 0.5489 (то есть, он остался на том же уровне), а F1-Score немного улучшился с 0.5086 до 0.5112. Однако ROC-AUC немного снизился с 0.7342 до 0.7333.\n",
    "\n",
    "Для регрессии метрики также остались близкими, но MSE немного увеличился с 1591379072.4324 до 1591520761.8251. R² не изменился (0.7982)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e029955-ce0e-4863-9fd4-574b14537b6f",
   "metadata": {},
   "source": [
    "## j. Выводы:\n",
    "Классификация:\n",
    "\n",
    "Результаты классификации остались на схожем уровне после применения улучшений. Это может свидетельствовать о том, что выбранная модель (логистическая регрессия) с текущими гиперпараметрами и применёнными улучшениями не дала значительного прироста в точности. Это может означать, что логистическая регрессия не является достаточно мощной для данного набора данных или что дополнительные улучшения, такие как изменение модели или более сложная обработка данных, могут быть полезны.\n",
    "\n",
    "Регрессия:\n",
    "\n",
    "Метрики регрессии также остались практически без изменений после улучшений. Это говорит о том, что линейная регрессия в этом случае также не продемонстрировала значительного улучшения. Однако, результаты по R² (0.7982) всё же указывают на довольно хорошее качество модели.\n",
    "\n",
    "Общие выводы:\n",
    "\n",
    "В целом, улучшения (кросс-валидация, поиск гиперпараметров) не привели к значительным изменениям в метриках. Это может свидетельствовать о том, что базовые модели логистической и линейной регрессии с данными параметрами уже достаточно эффективны для данного набора данных.\n",
    "Возможно, потребуется применить другие модели (например, случайный лес, градиентный бустинг) или дополнительные шаги по обработке данных (например, добавление новых признаков или использование более сложных методов нормализации).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aae81-d917-45ed-ab03-2d5d58230cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
